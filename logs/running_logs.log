[2025-08-04 21:33:10,158|(ERROR)| File: cli | Message: No server object found in /media/kirti/Dev/GenAI/E2E_Job_Recommender/main.py. Please either:
1. Use a standard variable name (mcp, server, or app)
2. Specify the object name with file:object syntax3. If the server creates the FastMCP object within main()    or another function, refactor the FastMCP object to be a    global variable named mcp, server, or app.]
[2025-08-04 21:33:42,830|(ERROR)| File: cli | Message: No server object found in /media/kirti/Dev/GenAI/E2E_Job_Recommender/main.py. Please either:
1. Use a standard variable name (mcp, server, or app)
2. Specify the object name with file:object syntax3. If the server creates the FastMCP object within main()    or another function, refactor the FastMCP object to be a    global variable named mcp, server, or app.]
[2025-08-04 21:34:19,095|(ERROR)| File: cli | Message: No server object found in /media/kirti/Dev/GenAI/E2E_Job_Recommender/main.py. Please either:
1. Use a standard variable name (mcp, server, or app)
2. Specify the object name with file:object syntax3. If the server creates the FastMCP object within main()    or another function, refactor the FastMCP object to be a    global variable named mcp, server, or app.]
[2025-08-04 21:46:14,546|(INFO)| File: server | Message: Processing request of type ListToolsRequest]
[2025-08-04 21:46:22,411|(INFO)| File: server | Message: Processing request of type CallToolRequest]
[2025-08-04 21:46:24,831|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 401 Unauthorized"]
[2025-08-04 21:46:34,675|(INFO)| File: server | Message: Processing request of type CallToolRequest]
[2025-08-04 21:46:35,780|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 401 Unauthorized"]
[2025-08-04 21:46:47,368|(INFO)| File: server | Message: Processing request of type CallToolRequest]
[2025-08-04 21:46:48,476|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 401 Unauthorized"]
[2025-08-04 21:49:12,324|(INFO)| File: server | Message: Processing request of type CallToolRequest]
[2025-08-04 21:49:13,555|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 401 Unauthorized"]
[2025-08-04 21:52:32,124|(INFO)| File: server | Message: Processing request of type ListToolsRequest]
[2025-08-04 21:52:39,007|(INFO)| File: server | Message: Processing request of type CallToolRequest]
[2025-08-04 21:52:40,434|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 401 Unauthorized"]
[2025-08-04 21:54:06,677|(INFO)| File: server | Message: Processing request of type CallToolRequest]
[2025-08-04 21:54:08,555|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 401 Unauthorized"]
[2025-08-04 21:55:05,022|(INFO)| File: server | Message: Processing request of type CallToolRequest]
[2025-08-04 21:55:06,119|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 401 Unauthorized"]
[2025-08-04 22:01:33,840|(INFO)| File: server | Message: Processing request of type ListToolsRequest]
[2025-08-04 22:01:41,200|(INFO)| File: server | Message: Processing request of type CallToolRequest]
[2025-08-04 22:01:43,193|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-04 22:01:43,495|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:43,810|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-04 22:01:44,096|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:44,398|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-04 22:01:45,477|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:45,536|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:45,677|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:46,771|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:48,062|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:49,392|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:50,690|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:51,987|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:53,272|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:54,567|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:55,853|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:57,146|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:58,422|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:01:59,706|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:00,985|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:02,249|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:03,545|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:04,862|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:06,161|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:07,436|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:08,733|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:10,013|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:11,306|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:12,607|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:13,904|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:15,200|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:16,501|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:17,781|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:19,062|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:20,356|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:21,648|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:22,950|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:24,239|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:25,512|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:26,791|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:28,071|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:29,381|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:30,674|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:31,957|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:33,262|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:34,563|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:35,853|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:37,141|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:38,428|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:39,702|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:41,008|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:42,292|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:43,580|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:44,884|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:46,168|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:46,237|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:47,455|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:48,742|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:50,025|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:51,302|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:52,595|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:53,908|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:55,226|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:56,511|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:57,809|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:02:59,098|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:00,394|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:01,682|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:02,975|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:04,253|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:05,533|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:06,815|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:08,101|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:09,429|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:10,728|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:12,009|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:13,297|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:14,591|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:15,875|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:17,158|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:18,474|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:19,752|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:21,037|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/Shie7rZ4wsjOWVSu1 "HTTP/1.1 200 OK"]
[2025-08-04 22:03:29,729|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/PvW1h0FSDCxqdEHuO/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-05 19:22:35,616|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 19:23:53,822|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 19:24:52,524|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 19:29:28,619|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 19:29:28,966|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 19:47:36,976|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 19:57:10,986|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 19:58:37,471|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 20:00:03,123|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 20:01:55,230|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.391916 seconds]
[2025-08-05 20:02:15,648|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.935661 seconds]
[2025-08-05 20:03:22,142|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 20:07:26,891|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 20:19:36,856|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 20:27:10,061|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 20:31:32,586|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 20:32:59,765|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 20:34:06,961|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 20:35:00,617|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 20:35:02,435|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 22:10:58,524|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:18:01,724|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 22:18:02,661|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 22:19:05,105|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:20:01,543|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:20:02,026|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 22:20:02,498|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 22:21:26,642|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:21:27,101|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 22:21:27,104|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 22:28:26,249|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:31:23,659|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:35:00,590|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:40:19,360|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:42:47,031|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-05 22:43:59,325|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:44:24,485|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:45:10,190|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-05 22:45:36,702|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 12:31:45,397|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 12:34:17,349|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:34:24,894|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 12:35:52,612|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:36:04,526|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:36:58,973|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:37:00,071|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:37:33,107|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 12:37:33,410|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 12:37:33,782|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:37:57,189|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:37:57,713|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:37:57,741|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 12:42:40,727|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:59:06,198|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 12:59:07,672|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 13:00:13,067|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 13:00:15,555|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 13:00:58,029|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 13:02:10,542|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 13:04:06,296|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 13:10:14,138|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 13:10:37,640|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 13:12:18,182|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 13:14:18,056|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 13:16:59,237|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 13:17:21,833|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 20:28:57,202|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 20:30:05,555|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 20:30:15,353|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 20:31:02,392|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 20:33:23,048|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 20:33:52,108|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 20:36:08,179|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 20:36:44,475|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 20:40:04,928|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 21:02:02,730|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 21:14:35,289|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 21:28:14,735|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 21:33:16,352|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 21:34:02,281|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 21:39:04,185|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.431865 seconds]
[2025-08-06 21:39:21,343|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.904398 seconds]
[2025-08-06 21:40:23,764|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 21:49:12,058|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 21:49:40,407|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 21:52:49,099|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:01:31,658|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:22:26,192|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:23:26,298|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:24:12,517|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:25:12,186|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:25:42,928|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:26:23,114|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:26:24,263|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:27:18,643|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:34:09,550|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:34:43,839|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:34:52,037|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:36:00,789|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:36:12,715|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:37:46,427|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:37:55,675|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:38:39,802|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:39:39,219|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:40:25,967|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:41:00,670|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:41:05,351|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:41:43,361|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:43:38,101|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:45:27,532|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:50:31,237|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:50:54,629|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:51:17,873|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:53:00,719|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:53:25,613|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 22:54:26,144|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:54:51,669|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:54:57,793|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:58:34,090|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 22:59:57,291|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:00:31,008|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:00:57,776|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:02:23,474|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:02:38,919|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:03:23,042|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:04:07,745|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:04:35,370|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:05:22,802|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:05:42,359|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:06:21,503|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:07:01,925|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:07:31,204|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:08:20,274|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:12:18,615|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:12:19,155|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:12:19,287|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 23:12:53,594|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:12:53,766|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:12:53,796|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 23:12:53,958|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:13:34,563|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:13:43,962|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:14:14,636|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:14:15,291|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:14:15,957|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-06 23:14:15,983|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:14:26,957|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:14:27,214|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:14:27,253|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-06 23:14:27,399|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:16:56,166|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:17:09,958|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:17:30,812|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:18:01,932|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:18:28,339|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:19:31,562|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:19:31,807|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:19:32,483|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:19:33,091|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:25:55,485|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:29:20,152|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:30:23,594|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:39:48,850|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:45:56,787|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:46:15,811|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-07 13:46:40,645|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:47:49,066|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:47:57,653|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:48:11,268|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:48:48,090|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-07 13:48:55,037|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:49:41,498|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:52:23,832|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:52:45,243|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:54:23,554|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:55:16,056|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 13:57:08,402|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-07 13:57:48,738|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-07 13:58:41,787|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-07 13:59:40,243|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 14:10:50,344|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 14:11:09,394|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 14:11:28,351|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 14:12:48,720|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 14:13:41,024|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:06:30,537|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:06:30,678|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:06:30,790|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:13:26,811|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:18:44,403|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:21:10,888|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:24:17,476|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:25:37,929|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:26:25,271|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:26:44,866|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:27:37,933|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:28:24,322|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:29:03,293|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:29:59,301|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:32:00,210|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:32:23,817|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 15:32:52,852|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:30:23,629|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:30:24,532|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:30:24,937|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:32:36,385|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:32:36,455|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:32:36,773|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:33:28,432|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:33:28,472|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:33:28,886|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:35:40,629|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:35:40,781|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:35:40,816|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:41:46,619|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:48:40,706|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:49:26,194|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:50:37,935|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-07 18:51:56,954|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-13 20:49:42,343|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-13 20:55:14,588|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-13 20:55:15,207|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:15,556|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-13 20:55:16,127|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:16,721|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-13 20:55:17,988|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:17,999|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-13 20:55:18,117|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-13 20:55:19,321|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:20,644|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:21,968|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:23,310|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:24,630|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:26,135|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:27,497|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:28,837|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:30,168|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:31,501|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:33,043|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:34,375|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:35,731|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:37,106|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:38,433|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:39,753|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:41,063|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:42,379|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:43,731|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:45,111|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:46,437|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:47,782|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:49,126|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:50,456|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:51,782|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:53,114|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:54,419|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:55,741|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:57,066|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:58,404|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:55:59,724|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:01,079|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:02,442|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:03,806|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:05,169|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:06,519|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:08,660|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:10,280|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:11,637|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:12,976|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:14,305|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:15,637|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:16,971|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:18,395|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:18,688|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-13 20:56:19,735|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:21,085|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:22,443|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:24,899|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:26,273|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:27,621|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:28,979|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:30,339|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:31,669|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:33,033|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:34,393|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:35,722|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:37,046|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:38,393|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:39,753|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:41,078|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:42,419|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:43,822|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:45,163|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:46,505|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:47,843|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:49,180|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:50,512|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:51,843|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:53,169|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:54,490|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:55,806|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:57,114|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:56:58,439|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:57:00,193|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/NJQqf9ht0spivgjsR "HTTP/1.1 200 OK"]
[2025-08-13 20:57:02,767|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/PvV08Lal3wBpAE5Nj/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-13 21:00:02,490|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 400 Bad Request"]
[2025-08-13 21:02:51,106|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 400 Bad Request"]
[2025-08-13 21:07:33,237|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 201 Created"]
[2025-08-13 21:07:33,595|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:33,912|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-13 21:07:34,244|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:34,551|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-13 21:07:35,789|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:35,872|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-13 21:07:36,215|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-13 21:07:37,114|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:38,455|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:40,219|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:41,622|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:42,986|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:44,321|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:45,638|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:46,961|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/koh3TWB9wmkKPcXSw "HTTP/1.1 200 OK"]
[2025-08-13 21:07:49,143|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/Si4rBLStwqYHfDEHm/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-14 13:32:20,996|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-14 13:35:37,066|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-14 13:40:02,374|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-14 13:40:43,003|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-14 13:41:08,425|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-14 13:42:52,558|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-14 13:44:06,375|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-14 13:49:33,067|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-14 13:51:12,438|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-14 14:04:19,336|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-14 14:12:12,788|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-14 14:13:06,037|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-14 14:18:30,621|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-14 14:18:40,970|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-14 14:18:55,395|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-14 14:19:03,522|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-14 14:19:03,859|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:04,568|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-14 14:19:05,180|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:05,542|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-14 14:19:06,742|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:06,872|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-14 14:19:06,926|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-14 14:19:08,043|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:09,430|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:10,746|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:12,113|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:13,847|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:15,989|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:17,555|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:18,857|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:20,160|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:21,454|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:22,749|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:24,044|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:25,365|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:26,665|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:27,957|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:29,270|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:30,574|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:31,879|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:33,201|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:34,514|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:35,816|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:37,118|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:38,424|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:39,722|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:41,023|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:42,324|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:43,638|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:44,940|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:46,374|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:47,682|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:49,015|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:50,299|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:51,695|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:53,071|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:54,418|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:55,734|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:57,032|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:58,350|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:19:59,711|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:01,024|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:02,374|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:03,741|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:05,044|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:06,445|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:07,546|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-14 14:20:07,942|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:09,563|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:11,218|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:12,560|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:13,909|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:15,219|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:16,568|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:17,866|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:19,377|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:20,835|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:22,238|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:23,552|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:24,899|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:26,192|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:27,558|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:28,905|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:30,218|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:31,519|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:32,915|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:34,399|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:36,005|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:37,415|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:38,762|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:40,069|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:41,366|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:42,728|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:44,042|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:45,388|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:46,703|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:48,808|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:50,101|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:51,469|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:52,777|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:54,130|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:55,460|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:56,791|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/jzBooVRTocpJydceQ "HTTP/1.1 200 OK"]
[2025-08-14 14:20:57,549|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/aeuEvBPKbO2B8b4ll/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-18 14:02:05,463|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 14:02:08,313|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:02:09,165|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:02:09,167|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:02:09,168|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:02:09,508|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:02:09,510|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:02:09,510|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:02:09,871|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:02:09,872|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:02:09,873|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:02:10,323|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:02:10,324|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:02:10,413|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:02:10,769|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:02:10,771|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:02:10,772|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:02:11,178|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:02:11,179|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:02:11,180|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:02:11,560|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:02:11,561|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:02:11,562|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:02:11,969|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:02:11,970|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:04:52,311|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 14:04:54,597|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:04:55,500|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:04:55,502|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:04:55,503|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:04:55,858|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:04:55,860|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:04:55,861|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:04:56,227|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:04:56,228|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:04:56,229|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:04:56,708|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:04:56,710|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:04:56,730|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:04:57,091|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:04:57,093|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:04:57,093|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:04:57,483|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:04:57,484|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:04:57,484|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:04:57,836|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:04:57,838|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:04:57,838|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:04:58,247|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:04:58,248|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:06:12,011|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 14:06:14,019|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:06:14,927|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:06:14,929|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:06:14,930|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:06:15,342|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:06:15,344|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:06:15,345|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:06:15,758|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:06:15,759|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:06:15,760|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:06:16,298|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:06:16,301|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:06:16,342|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:06:17,006|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:06:17,008|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:06:17,009|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:06:17,536|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:06:17,538|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:06:17,910|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:06:18,307|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:06:18,309|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:06:18,310|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:06:18,735|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:06:18,737|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:07:45,662|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 14:07:47,450|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:07:48,458|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:07:48,460|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:07:48,461|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:07:48,841|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:07:48,843|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:07:48,843|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:07:49,193|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:07:49,195|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:07:49,196|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:07:49,700|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:07:49,701|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:07:49,724|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:07:50,091|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:07:50,093|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:07:50,094|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:07:50,481|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:07:50,483|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:07:50,483|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:07:50,843|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:07:50,845|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:07:51,116|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:07:51,458|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:07:51,459|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:09:44,778|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 14:09:46,488|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:09:47,193|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:09:47,195|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:09:47,196|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:09:47,537|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:09:47,538|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:09:47,539|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:09:47,956|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:09:47,958|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:09:47,958|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:09:48,412|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:09:48,413|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:09:48,435|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:09:48,818|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:09:48,820|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:09:48,820|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:09:49,166|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:09:49,167|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:09:49,168|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:09:49,506|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:09:49,507|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:09:49,508|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:09:49,895|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:09:49,897|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:10:55,133|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 14:10:56,940|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:10:57,608|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:10:57,610|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:10:57,610|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:10:57,964|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:10:57,965|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:10:57,966|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:10:58,375|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:10:58,376|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:10:58,377|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:10:58,851|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:10:58,853|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:10:58,873|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:10:59,273|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:10:59,275|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:10:59,276|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:10:59,695|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:10:59,697|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:10:59,698|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:11:00,041|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:11:00,042|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:11:00,043|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:11:00,406|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:11:00,407|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:12:11,063|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 14:12:13,181|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:12:14,056|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:12:14,059|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:12:14,060|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:12:14,470|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:12:14,471|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:12:14,472|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:12:14,877|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:12:14,879|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:12:14,880|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:12:15,447|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:12:15,448|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:12:15,475|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:12:15,925|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:12:15,927|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:12:15,928|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:12:16,355|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:12:16,356|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:12:16,405|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:12:16,827|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:12:16,828|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:12:16,829|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:12:17,243|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:12:17,244|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:15:18,367|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 14:15:20,460|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:15:21,180|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:15:21,183|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:15:21,183|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:15:21,548|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:15:21,549|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:15:21,550|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:15:21,892|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:15:21,894|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:15:21,895|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:15:22,247|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:15:22,249|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:15:22,266|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:15:22,712|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:15:22,714|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:15:22,714|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:15:23,230|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:15:23,231|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:15:23,232|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:15:23,581|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:15:23,582|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:15:23,583|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:15:23,949|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:15:23,951|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:17:33,455|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 14:17:35,115|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:17:35,894|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:17:35,896|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:17:35,896|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:17:36,270|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:17:36,272|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:17:36,272|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:17:36,657|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:17:36,659|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:17:36,659|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:17:37,018|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:17:37,019|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:17:37,037|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:17:37,403|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:17:37,404|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:17:37,405|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:17:38,049|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:17:38,050|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:17:38,051|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:17:38,386|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:17:38,388|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:17:38,388|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:17:38,744|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:17:38,745|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:18:03,988|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 14:18:04,368|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 14:18:04,370|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 14:18:04,370|(INFO)| File: ask_llm | Message: Running chain for keywords.]
[2025-08-18 14:18:04,740|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-18 14:18:05,855|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-18 14:18:05,938|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-18 14:18:17,878|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-18 14:18:18,209|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:18,508|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-18 14:18:18,793|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:19,078|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-18 14:18:20,231|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:20,252|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-18 14:18:20,410|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-18 14:18:21,553|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:22,854|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:24,170|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:25,494|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:26,812|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:28,933|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:30,487|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:31,802|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:33,112|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:34,440|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:35,752|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:37,068|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:38,375|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:39,667|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:40,995|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:42,296|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:43,598|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:44,920|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:46,220|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:47,515|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:49,241|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:50,811|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:52,126|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:53,442|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:54,775|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:56,141|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:57,453|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:18:58,768|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:00,099|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:01,454|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:02,790|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:04,121|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:05,451|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:06,760|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:08,088|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:09,409|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:10,732|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:12,057|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:13,385|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:14,702|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:16,008|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:17,318|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:18,650|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:19,942|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:20,967|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-18 14:19:21,251|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:22,541|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:23,850|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:25,152|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:26,456|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:27,769|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:29,073|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:30,366|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:31,737|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:33,050|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:34,377|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:35,756|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:37,084|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:38,393|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:39,711|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:40,990|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:42,298|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:43,649|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:44,955|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:46,278|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:47,609|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:48,927|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:50,347|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:51,650|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:52,967|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:55,835|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:57,432|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:19:58,750|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:20:00,075|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/c2UbqMgih6My4XYWz "HTTP/1.1 200 OK"]
[2025-08-18 14:20:05,560|(ERROR)| File: linkedin | Message: 🔥 Error fetching LinkedIn jobs: peer closed connection without sending complete message body (incomplete chunked read)]
[2025-08-18 14:20:05,561|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 14:20:05,562|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: context must include a "request" key]
[2025-08-18 15:18:38,698|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 15:18:40,322|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:18:41,020|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:18:41,022|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:18:41,022|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:18:41,443|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:18:41,445|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:18:41,445|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:18:41,855|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:18:41,856|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:18:41,857|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:18:42,253|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:18:42,254|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:18:42,280|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:18:43,027|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:18:43,031|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:18:43,210|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:18:43,629|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:18:43,630|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:18:43,630|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:18:43,991|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:18:43,993|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:18:43,993|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:18:44,340|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:18:44,341|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:19:04,117|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:19:04,704|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:19:04,705|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:19:04,706|(INFO)| File: ask_llm | Message: Running chain for keywords.]
[2025-08-18 15:19:04,816|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-18 15:19:07,142|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-18 15:19:07,241|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-18 15:19:26,175|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 15:21:44,873|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 15:21:46,869|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:21:47,571|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:21:47,573|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:21:47,574|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:21:47,924|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:21:47,926|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:21:47,927|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:21:48,313|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:21:48,315|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:21:48,315|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:21:49,008|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:21:49,009|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:21:49,034|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:21:49,714|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:21:49,715|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:21:49,716|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:21:50,371|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:21:50,373|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:21:50,374|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:21:50,891|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:21:50,894|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:21:50,896|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:21:51,359|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:21:51,361|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:22:04,531|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:22:04,896|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:22:04,897|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:22:04,898|(INFO)| File: ask_llm | Message: Running chain for keywords.]
[2025-08-18 15:22:05,001|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-18 15:22:06,095|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-18 15:22:06,102|(ERROR)| File: job_recommendation | Message: Error while generating keywords: Error code: 400 - {'error': {'message': "tool call validation failed: parameters for tool Keywords did not match schema: errors: [missing properties: 'keywords']", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool-use>\n{\n  "tool_call": {\n    "id": "pending",\n    "type": "function",\n    "function": {\n      "name": "Keywords"\n    },\n    "parameters": {\n      "properties": {\n        "keywords": [\n          "Artificial Intelligence",\n          "Machine Learning",\n          "Data Science",\n          "Python",\n          "PyTorch"\n        ]\n      }\n    }\n  }\n}\n</tool-use>'}}]
[2025-08-18 15:48:40,787|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 15:48:42,419|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:48:43,124|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:48:43,126|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:48:43,127|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:48:43,567|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:48:43,569|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:48:43,569|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:48:43,959|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:48:43,961|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:48:43,961|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:48:44,375|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:48:44,376|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:48:44,401|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:48:44,773|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:48:44,775|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:48:44,921|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:48:45,273|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:48:45,275|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:48:45,275|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:48:45,641|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:48:45,642|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:48:45,643|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:48:45,990|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:48:45,991|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:49:43,832|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-18 15:49:43,833|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'list' object has no attribute 'keywords']
[2025-08-18 15:50:58,212|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 15:50:59,862|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:51:00,548|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:51:00,550|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:51:00,551|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:51:00,905|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:51:00,906|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:51:00,907|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:51:01,293|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:51:01,294|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:51:01,295|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:51:01,656|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:51:01,657|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:51:01,676|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:51:02,047|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:51:02,048|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:51:02,199|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:51:02,710|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:51:02,711|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:51:02,712|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:51:03,096|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:51:03,097|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:51:03,098|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:51:03,457|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:51:03,458|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:51:19,395|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-18 15:51:19,396|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'dict' object has no attribute 'keywords']
[2025-08-18 15:52:51,048|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 15:52:53,029|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:52:53,806|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:52:53,808|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:52:53,809|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:52:54,233|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:52:54,234|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:52:54,235|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:52:54,605|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:52:54,607|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:52:54,607|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:52:54,960|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:52:54,962|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:52:54,986|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:52:55,411|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:52:55,413|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:52:55,561|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:52:55,912|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:52:55,913|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:52:55,914|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:52:56,337|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:52:56,338|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:52:56,339|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 15:52:56,697|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 15:52:56,698|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 15:56:08,835|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-18 15:56:41,564|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 16:07:44,968|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:07:48,482|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:07:49,568|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:07:49,573|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:07:49,574|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:07:50,098|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:07:50,100|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:07:50,100|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:07:50,529|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:07:50,531|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:07:50,532|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:07:50,941|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:07:50,943|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:07:50,962|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:07:51,452|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:07:51,453|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:07:51,588|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:07:52,342|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:07:52,344|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:07:52,345|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:07:52,887|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:07:52,891|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:07:52,891|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:07:53,751|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:07:53,753|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:09:07,082|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-18 16:09:14,641|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 16:27:45,422|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:27:47,107|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:27:47,852|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:27:47,853|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:27:47,854|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:27:48,575|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:27:48,577|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:27:48,578|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:27:49,000|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:27:49,001|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:27:49,002|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:27:49,476|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:27:49,477|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:27:49,502|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:27:49,888|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:27:49,889|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:27:50,035|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:27:50,408|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:27:50,410|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:27:50,410|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:27:50,776|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:27:50,778|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:27:50,778|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:27:51,138|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:27:51,140|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:37:05,301|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:38:00,333|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:40:37,959|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:40:41,817|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:40:42,869|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:40:42,874|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:40:42,875|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:40:43,311|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:40:43,313|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:40:43,313|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:40:43,771|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:40:43,773|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:40:43,773|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:40:44,122|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:40:44,123|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:40:44,141|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:40:44,541|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:40:44,542|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:40:44,543|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:40:44,927|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:40:44,929|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:40:44,929|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:40:45,346|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:40:45,348|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:40:45,348|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:40:45,848|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:40:45,850|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:15,114|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:44:18,824|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:20,142|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:20,145|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:20,146|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:20,780|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:20,782|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:20,783|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:21,284|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:21,285|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:21,286|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:21,821|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:21,825|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:21,858|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:22,522|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:22,524|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:22,525|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:22,960|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:22,962|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:22,963|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:24,288|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:24,291|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:24,292|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:25,031|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:25,034|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:42,936|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:44:46,768|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:48,122|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:48,125|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:48,126|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:48,726|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:48,727|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:48,728|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:49,652|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:49,654|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:49,655|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:50,282|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:50,284|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:50,317|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:50,898|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:50,900|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:50,900|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:51,471|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:51,473|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:51,474|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:52,566|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:52,569|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:44:52,570|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:44:53,160|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:44:53,162|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:45:45,163|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:45:49,939|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:45:51,987|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:45:52,003|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:45:52,005|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:45:52,862|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:45:52,864|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:45:52,864|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:45:53,598|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:45:53,600|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:45:53,601|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:45:54,330|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:45:54,334|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:45:54,384|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:45:55,213|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:45:55,225|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:45:55,226|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:45:56,084|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:45:56,087|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:45:56,089|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:45:56,946|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:45:56,950|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:45:56,951|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:45:57,603|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:45:57,606|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:46:04,405|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:46:06,441|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:46:07,298|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:46:07,301|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:46:07,301|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:46:07,695|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:46:07,696|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:46:07,697|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:46:08,049|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:46:08,051|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:46:08,052|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:46:08,411|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:46:08,412|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:46:08,438|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:46:08,834|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:46:08,835|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:46:08,835|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:46:09,200|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:46:09,201|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:46:09,202|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:46:09,544|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:46:09,545|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:46:09,546|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:46:09,893|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:46:09,894|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:28,464|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:54:33,203|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:35,602|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:35,606|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:35,607|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:36,284|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:36,286|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:36,287|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:37,030|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:37,034|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:37,037|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:38,415|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:38,420|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:38,464|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:39,262|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:39,264|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:39,265|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:39,999|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:40,001|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:40,001|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:40,706|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:40,708|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:40,709|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:41,399|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:41,402|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:53,114|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:54:56,950|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:58,559|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:58,570|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:58,574|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:54:59,276|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:54:59,280|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:54:59,281|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:00,055|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:00,057|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:00,058|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:00,733|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:00,735|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:00,772|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:01,444|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:01,447|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:01,447|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:02,105|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:02,111|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:02,112|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:03,100|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:03,102|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:03,103|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:03,760|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:03,762|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:12,412|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:55:16,608|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:18,839|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:18,842|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:18,843|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:19,855|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:19,857|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:19,858|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:20,503|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:20,504|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:20,505|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:21,145|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:21,147|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:21,191|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:21,875|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:21,883|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:21,890|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:23,483|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:23,485|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:23,486|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:24,139|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:24,142|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:55:24,143|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:55:24,858|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:55:24,863|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:23,884|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:57:29,760|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:32,718|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:32,721|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:32,723|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:33,422|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:33,424|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:33,425|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:34,274|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:34,276|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:34,277|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:35,065|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:35,069|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:44,505|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:57:48,504|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:50,784|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:50,790|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:50,790|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:51,475|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:51,478|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:51,479|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:52,115|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:52,117|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:52,119|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:52,699|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:52,700|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:52,729|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:53,353|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:53,354|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:53,355|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:53,967|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:53,973|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:53,976|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:54,744|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:54,748|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:57:54,749|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:57:55,430|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:57:55,431|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:58:02,454|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:58:04,834|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:58:06,773|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:58:06,786|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:58:06,787|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:58:07,419|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:58:07,421|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:58:07,422|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:58:07,899|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:58:07,901|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:58:07,901|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:58:08,435|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:58:08,437|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:58:08,469|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:58:09,134|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:58:09,138|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:58:09,141|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:58:09,795|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:58:09,796|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:58:09,797|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:58:10,389|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:58:10,391|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:58:10,392|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:58:10,957|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:58:10,958|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:59:21,956|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 16:59:25,312|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:59:27,910|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:59:27,915|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:59:27,917|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:59:28,638|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:59:28,641|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:59:28,642|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:59:29,337|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:59:29,340|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:59:29,342|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:59:30,031|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:59:30,033|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:59:30,072|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:59:30,727|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:59:30,730|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:59:30,732|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:59:31,736|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:59:31,738|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:59:31,739|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:59:32,427|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:59:32,429|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:59:32,430|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 16:59:33,298|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 16:59:33,306|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 16:59:37,610|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 17:00:57,520|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:01:03,421|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:05,694|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:05,711|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:05,712|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:06,951|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:06,954|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:06,956|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:08,976|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:08,978|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:08,987|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:10,294|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:10,296|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:10,337|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:11,012|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:11,014|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:11,015|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:11,732|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:11,734|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:11,736|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:13,469|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:13,472|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:13,474|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:14,250|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:14,252|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:28,717|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:01:31,073|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:31,866|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:31,868|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:31,869|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:32,220|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:32,221|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:32,222|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:32,581|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:32,582|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:32,583|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:32,924|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:32,926|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:32,947|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:33,348|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:33,349|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:33,350|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:33,687|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:33,689|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:33,689|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:34,027|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:34,028|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:01:34,029|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:01:34,381|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:01:34,384|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:31,360|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:02:35,111|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:36,586|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:36,590|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:36,592|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:37,270|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:37,272|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:37,273|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:37,954|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:37,959|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:37,964|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:38,889|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:38,892|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:38,929|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:39,629|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:39,631|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:39,632|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:40,303|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:40,304|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:40,305|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:41,010|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:41,012|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:41,013|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:41,743|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:41,746|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:50,469|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:02:54,186|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:56,255|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:56,259|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:56,260|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:56,900|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:56,902|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:56,903|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:57,560|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:57,563|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:57,564|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:58,200|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:58,204|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:58,247|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:58,874|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:58,877|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:58,880|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:02:59,565|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:02:59,567|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:02:59,568|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:00,228|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:00,231|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:00,233|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:01,090|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:01,093|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:22,587|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:03:27,485|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:29,142|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:29,145|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:29,146|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:30,107|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:30,109|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:30,110|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:31,609|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:31,611|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:31,612|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:32,316|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:32,317|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:32,353|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:32,996|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:32,999|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:33,000|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:34,559|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:34,579|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:34,583|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:35,746|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:35,749|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:35,755|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:36,536|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:36,538|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:45,335|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:03:48,085|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:49,002|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:49,006|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:49,007|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:49,400|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:49,402|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:49,403|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:49,849|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:49,851|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:49,852|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:50,369|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:50,371|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:50,402|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:50,908|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:50,910|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:50,910|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:51,394|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:51,396|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:51,396|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:52,070|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:52,071|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:03:52,072|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:03:52,572|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:03:52,574|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:04:24,428|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-18 17:04:24,790|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:26,338|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-18 17:04:26,651|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:26,951|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-18 17:04:28,252|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-18 17:04:28,267|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-18 17:04:29,500|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:30,814|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:32,143|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:33,497|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:34,803|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:36,108|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:38,563|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:39,863|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:41,168|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:42,462|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:44,275|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:45,564|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:46,866|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:48,164|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:49,463|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:50,767|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:52,073|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:53,402|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:55,572|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:57,138|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:58,685|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:04:59,985|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:01,305|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:02,620|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:03,969|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:05,267|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:06,602|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:07,907|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:09,220|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:10,560|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:11,874|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:13,194|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:14,504|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:15,814|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:17,140|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:18,456|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:19,766|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:21,083|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:22,391|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:23,757|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:25,088|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:26,405|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:27,725|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:28,842|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-18 17:05:29,091|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:30,446|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:31,772|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:33,088|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:34,415|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:35,733|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:37,055|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:38,391|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:39,733|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:41,027|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:42,322|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:43,657|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:44,963|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:46,685|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:48,273|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:49,571|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:50,868|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:52,188|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:53,489|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:54,822|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:56,160|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:57,469|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:05:58,837|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:00,174|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:01,500|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:02,827|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:04,912|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:06,483|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:08,051|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:09,363|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:10,699|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:12,000|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:13,305|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:14,610|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:15,929|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:17,261|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:18,562|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:19,868|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:21,176|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:22,482|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:23,798|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:25,125|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:26,430|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:27,794|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:29,123|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:30,460|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:31,773|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:33,085|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/cGb5G3sv5vm4WChWf "HTTP/1.1 200 OK"]
[2025-08-18 17:06:34,166|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/fbJLmzEHD6RARWkFC/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-18 17:06:48,018|(INFO)| File: linkedin | Message: ✅ Retrieved 100 items from dataset: fbJLmzEHD6RARWkFC]
[2025-08-18 17:06:48,019|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 17:06:48,019|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: list indices must be integers or slices, not str]
[2025-08-18 17:07:54,770|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:07:58,109|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:07:59,529|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:07:59,534|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:07:59,535|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:00,180|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:00,182|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:00,182|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:00,874|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:00,880|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:00,886|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:01,599|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:01,601|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:01,639|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:02,295|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:02,297|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:02,298|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:02,946|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:02,948|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:02,949|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:05,016|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:05,017|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:05,018|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:05,664|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:05,666|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:15,751|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:08:20,006|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:23,019|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:23,036|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:23,058|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:25,390|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:25,395|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:25,396|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:26,411|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:26,416|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:26,418|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:27,304|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:27,306|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:27,342|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:28,008|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:28,011|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:28,012|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:28,677|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:28,679|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:28,679|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:29,794|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:29,797|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:29,798|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:30,549|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:30,550|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:40,507|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:08:43,110|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:44,384|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:44,388|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:44,389|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:44,763|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:44,766|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:44,766|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:45,121|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:45,122|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:45,123|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:45,572|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:45,573|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:45,602|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:46,063|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:46,065|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:46,066|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:46,489|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:46,490|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:46,491|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:46,954|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:46,955|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:46,956|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:47,360|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:47,361|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:53,401|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:08:55,640|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:57,388|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:57,391|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:57,392|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:58,022|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:58,024|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:58,025|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:08:58,945|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:08:58,957|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:08:58,963|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:00,044|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:00,046|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:00,082|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:00,765|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:00,767|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:00,769|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:01,425|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:01,429|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:01,430|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:02,097|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:02,102|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:02,103|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:03,117|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:03,118|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:11,983|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:09:15,483|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:17,304|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:17,307|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:17,308|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:18,769|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:18,786|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:18,787|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:19,696|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:19,697|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:19,698|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:21,297|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:21,318|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:21,583|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:22,339|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:22,341|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:22,342|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:22,978|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:22,980|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:22,980|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:23,602|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:23,603|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:09:23,604|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:09:24,244|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:09:24,247|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:07,701|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:10:11,543|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:13,232|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:13,236|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:13,237|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:13,994|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:13,998|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:13,999|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:14,934|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:14,941|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:14,947|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:15,874|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:15,876|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:15,910|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:16,550|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:16,553|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:16,555|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:17,185|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:17,187|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:17,189|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:17,815|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:17,819|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:17,821|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:18,448|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:18,450|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:33,838|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 17:10:36,479|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:37,967|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:37,970|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:37,972|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:38,408|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:38,410|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:38,410|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:38,754|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:38,755|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:38,756|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:39,132|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:39,133|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:39,156|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:39,569|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:39,570|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:39,571|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:39,942|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:39,943|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:39,944|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:40,322|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:40,323|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:10:40,324|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 17:10:40,683|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 17:10:40,684|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 17:11:15,119|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-18 17:11:15,682|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:16,944|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-18 17:11:17,316|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:17,629|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-18 17:11:18,836|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:18,856|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-18 17:11:18,970|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-18 17:11:20,147|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:21,464|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:22,798|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:25,181|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:26,595|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:27,950|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:29,587|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:31,215|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:32,510|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:33,813|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:35,199|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:36,501|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:37,795|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:39,092|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:40,855|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:43,321|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:44,614|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:46,004|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:47,298|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:48,642|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:49,948|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:51,247|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:52,943|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:54,445|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:56,560|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:11:58,820|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:00,934|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:04,511|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:05,801|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:07,823|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:09,140|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:11,147|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:12,439|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:13,741|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:15,140|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:16,425|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:17,718|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:19,015|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:19,500|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-18 17:12:20,888|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:22,753|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:24,105|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:25,414|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:27,261|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:28,534|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:29,883|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:32,100|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:33,421|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:36,602|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:41,719|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:44,003|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:45,321|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:46,826|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:48,093|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:49,400|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:53,971|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:55,302|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:56,584|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:57,884|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:12:59,263|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:13:00,554|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/s8HFa9fdhebP7ykzD "HTTP/1.1 200 OK"]
[2025-08-18 17:13:01,085|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/WH96114XILKHjl3m0/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-18 17:13:08,497|(INFO)| File: linkedin | Message: ✅ Retrieved 98 items from dataset: WH96114XILKHjl3m0]
[2025-08-18 17:13:08,502|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 18:48:24,811|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 18:50:09,957|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 18:50:15,868|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:50:17,537|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:50:17,541|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:50:17,542|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:50:18,404|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:50:18,406|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:50:18,407|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:50:18,809|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:50:18,811|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:50:18,811|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:50:19,203|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:50:19,204|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:50:19,260|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:50:19,605|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:50:19,606|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:50:19,607|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:50:19,972|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:50:19,973|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:50:19,974|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:50:20,629|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:50:20,632|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:50:20,633|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:50:21,331|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:50:21,340|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:50:39,213|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 18:50:39,288|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 18:51:35,128|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 18:51:40,542|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:51:43,195|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:51:43,198|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:51:43,206|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:51:44,382|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:51:44,384|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:51:44,384|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:51:45,437|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:51:45,446|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:51:45,447|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:51:46,362|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:51:46,364|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:51:46,421|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:51:47,329|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:51:47,334|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:51:47,336|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:51:48,113|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:51:48,116|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:51:48,117|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:51:48,820|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:51:48,830|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:51:48,834|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:51:49,860|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:51:49,862|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:09,643|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 18:52:17,196|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:52:20,147|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:52:20,151|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:20,154|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:52:21,676|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:52:21,678|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:21,678|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:52:22,710|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:52:22,712|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:22,712|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:52:24,029|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:52:24,050|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:24,139|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:52:25,124|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:52:25,126|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:25,128|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:52:26,357|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:52:26,359|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:26,363|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:52:27,477|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:52:27,481|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:27,482|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:52:28,947|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:52:28,957|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:45,325|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 18:52:53,782|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:52:58,368|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:52:58,378|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:52:58,379|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:53:00,157|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:53:00,159|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:53:00,159|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:53:01,316|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:53:01,327|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:53:01,328|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:53:02,750|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:53:02,755|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:53:02,852|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:53:04,526|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:53:04,540|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:53:04,546|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:53:05,988|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:53:05,993|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:53:06,001|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:53:07,723|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:53:07,753|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:53:07,769|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:53:09,446|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:53:09,461|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:53:38,381|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 18:53:38,456|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 18:57:36,190|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 18:57:39,425|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:40,187|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:40,189|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:40,189|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:40,590|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:40,592|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:40,593|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:41,008|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:41,010|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:41,011|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:41,424|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:41,426|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:41,451|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:41,887|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:41,889|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:41,889|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:42,357|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:42,360|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:42,361|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:42,930|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:42,932|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:42,933|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:43,862|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:43,865|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:51,990|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 18:57:54,132|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:55,037|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:55,039|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:55,040|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:55,442|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:55,443|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:55,444|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:55,858|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:55,860|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:55,860|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:56,316|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:56,317|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:56,342|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:56,745|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:56,747|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:56,748|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:57,155|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:57,157|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:57,157|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:57,544|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:57,546|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:57:57,547|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:57:57,957|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:57:57,959|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:58:16,233|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 18:58:16,314|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 18:59:14,520|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 18:59:19,617|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:21,366|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:21,370|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:21,372|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:22,034|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:22,036|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:22,038|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:22,609|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:22,611|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:22,611|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:23,073|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:23,075|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:23,101|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:23,493|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:23,494|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:23,494|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:23,931|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:23,933|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:23,934|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:24,412|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:24,414|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:24,414|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:24,828|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:24,830|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:34,381|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 18:59:37,897|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:39,088|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:39,090|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:39,091|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:39,607|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:39,611|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:39,612|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:40,552|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:40,553|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:40,554|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:41,129|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:41,130|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:41,163|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:41,766|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:41,768|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:41,769|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:42,348|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:42,350|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:42,350|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:42,959|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:42,962|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:42,967|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 18:59:43,958|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 18:59:43,960|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 18:59:59,897|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 18:59:59,974|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 19:01:46,808|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 19:01:53,649|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:01:56,109|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:01:56,127|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:01:56,145|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:01:57,439|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:01:57,441|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:01:57,442|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:01:58,475|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:01:58,494|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:01:58,495|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:01:59,923|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:01:59,928|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:00,044|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:01,071|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:01,080|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:01,081|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:02,285|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:02,288|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:02,292|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:03,698|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:03,717|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:03,721|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:05,705|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:05,712|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:29,660|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 19:02:38,693|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:43,054|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:43,069|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:43,071|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:46,256|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:46,258|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:46,262|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:47,892|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:47,930|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:47,931|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:49,441|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:49,474|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:49,598|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:51,937|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:51,947|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:51,948|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:53,221|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:53,223|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:53,224|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:54,181|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:54,186|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:02:54,189|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:02:56,317|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:02:56,332|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:03:37,439|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 19:03:45,490|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:03:48,492|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:03:48,494|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:03:48,495|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:03:49,826|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:03:49,830|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:03:49,832|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:03:51,395|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:03:51,409|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:03:51,426|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:03:53,242|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:03:53,244|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:03:53,355|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:03:54,917|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:03:54,922|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:03:54,929|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:03:56,059|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:03:56,070|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:03:56,071|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:03:58,348|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:03:58,350|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:03:58,351|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:04:00,504|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:04:00,507|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:04:25,857|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 19:04:30,501|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:04:31,770|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:04:31,776|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:04:31,777|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:04:32,442|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:04:32,443|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:04:32,445|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:04:33,089|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:04:33,098|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:04:33,099|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:04:33,787|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:04:33,789|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:04:33,831|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:04:34,545|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:04:34,547|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:04:34,548|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:04:35,212|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:04:35,214|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:04:35,215|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:04:36,208|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:04:36,218|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:04:36,219|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:04:37,276|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:04:37,278|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:04:37,343|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:04:37,435|(ERROR)| File: job_recommendation | Message: Error while cleaning job: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 19:04:37,435|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: 500: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 19:05:57,146|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 19:05:59,385|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:06:00,322|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:06:00,326|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:06:00,327|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:06:00,757|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:06:00,759|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:06:00,760|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:06:01,290|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:06:01,291|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:06:01,292|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:06:01,786|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:06:01,787|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:06:01,816|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:06:02,591|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:06:02,593|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:06:02,596|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:06:03,325|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:06:03,327|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:06:03,328|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:06:04,033|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:06:04,036|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:06:04,036|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:06:04,656|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:06:04,658|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:06:32,579|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:06:32,665|(ERROR)| File: job_recommendation | Message: Error while cleaning job: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 19:06:32,667|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: 500: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 19:13:24,871|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 19:13:28,969|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:13:30,566|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:13:30,569|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:13:30,570|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:13:31,750|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:13:31,764|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:13:31,768|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:13:32,578|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:13:32,580|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:13:32,581|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:13:33,252|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:13:33,254|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:13:33,279|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:13:33,760|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:13:33,762|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:13:33,762|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:13:34,285|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:13:34,287|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:13:34,288|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:13:34,950|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:13:34,953|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:13:34,954|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:13:35,472|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:13:35,473|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:13:50,414|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:13:50,514|(ERROR)| File: job_recommendation | Message: Error while cleaning job: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 19:13:50,515|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: 500: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 19:14:30,683|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 19:14:34,584|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:14:35,804|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:14:35,807|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:14:35,808|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:14:36,409|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:14:36,411|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:14:36,412|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:14:37,166|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:14:37,168|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:14:37,169|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:14:37,915|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:14:37,917|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:14:37,952|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:14:38,640|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:14:38,642|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:14:38,643|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:14:39,419|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:14:39,421|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:14:39,428|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:14:40,064|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:14:40,066|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:14:40,066|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:14:40,605|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:14:40,607|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:14:51,212|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:14:51,329|(ERROR)| File: job_recommendation | Message: Error while cleaning job: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 19:14:51,337|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: 500: invalid decimal literal (<unknown>, line 3)]
[2025-08-18 19:16:32,962|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 19:16:42,597|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:16:46,469|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:16:46,486|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:16:46,490|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:16:47,902|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:16:47,908|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:16:47,912|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:16:50,311|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:16:50,317|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:16:50,318|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:16:51,581|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:16:51,584|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:16:51,672|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:16:52,600|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:16:52,608|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:16:52,609|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:16:53,492|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:16:53,495|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:16:53,496|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:16:54,785|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:16:54,800|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:16:54,808|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:16:56,529|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:16:56,534|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:17:19,851|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-18 19:17:26,483|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:17:28,047|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:17:28,051|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:17:28,052|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:17:28,671|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:17:28,673|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:17:28,674|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:17:29,285|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:17:29,286|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:17:29,287|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:17:29,903|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:17:29,906|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:17:29,963|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:17:30,586|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:17:30,589|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:17:30,591|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:17:31,325|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:17:31,327|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:17:31,329|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:17:31,963|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:17:31,965|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:17:31,966|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-18 19:17:32,656|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-18 19:17:32,658|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-18 19:17:32,716|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:17:33,029|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:17:51,058|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:17:51,371|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:20:45,487|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:20:45,903|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:23:58,554|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:23:58,738|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:25:45,667|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:25:45,901|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:27:45,654|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:27:45,863|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:39:33,421|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:39:33,677|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:43:42,182|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:43:42,411|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:44:59,611|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:44:59,929|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:46:11,319|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:46:12,067|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:46:31,912|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:46:32,148|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:46:54,498|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:46:55,381|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:47:26,266|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:47:26,568|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:47:35,557|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:47:35,786|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:48:04,129|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:48:04,479|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:48:59,214|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:48:59,503|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:49:16,633|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:49:16,921|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:50:53,214|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:50:53,467|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:51:24,268|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:51:24,785|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:55:56,024|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:55:56,489|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:57:10,193|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:57:10,365|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:57:48,119|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:57:48,380|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:57:58,858|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:57:59,053|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 19:59:46,633|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 19:59:46,825|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 20:00:05,292|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 20:00:05,462|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 20:00:22,728|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 20:00:22,940|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 20:03:46,483|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 20:03:46,835|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 20:10:33,408|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 20:10:33,993|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 20:13:46,805|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 20:13:46,996|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 20:14:33,790|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 20:14:33,992|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 20:15:43,705|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 20:15:44,088|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 20:17:52,529|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 20:17:52,738|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-18 20:21:10,750|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-18 20:21:10,983|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 14:11:47,609|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 14:11:50,298|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:11:51,488|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:11:51,490|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:11:51,491|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:11:51,834|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:11:51,835|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:11:51,836|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:11:52,179|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:11:52,180|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:11:52,181|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:11:52,532|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:11:52,533|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:11:52,592|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:11:52,951|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:11:52,953|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:11:52,953|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:11:53,303|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:11:53,304|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:11:53,305|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:11:53,687|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:11:53,689|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:11:53,689|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:11:54,130|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:11:54,131|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:12:31,306|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 14:12:31,723|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 14:18:36,344|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 14:18:40,311|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:18:42,089|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:18:42,091|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:18:42,092|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:18:42,722|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:18:42,725|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:18:42,726|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:18:43,284|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:18:43,285|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:18:43,286|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:18:43,814|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:18:43,818|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:18:43,889|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:18:44,567|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:18:44,570|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:18:44,571|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:18:45,186|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:18:45,187|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:18:45,189|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:18:45,814|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:18:45,817|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:18:45,818|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:18:46,325|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:18:46,326|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:19:54,584|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 400 Bad Request"]
[2025-08-19 14:19:54,588|(ERROR)| File: naukri | Message: 🔥 Error fetching Naukri jobs: Input is not valid: Field input.keyword must be string]
[2025-08-19 14:19:54,592|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 14:19:54,665|(ERROR)| File: job_recommendation | Message: Error while searching job from the naukri: 'ApifyApiError' object is not iterable]
[2025-08-19 14:20:44,271|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 400 Bad Request"]
[2025-08-19 14:20:44,276|(ERROR)| File: naukri | Message: 🔥 Error fetching Naukri jobs: Input is not valid: Field input.keyword must be string]
[2025-08-19 14:20:44,277|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 14:20:44,279|(ERROR)| File: job_recommendation | Message: Error while searching job from the naukri: 'ApifyApiError' object is not iterable]
[2025-08-19 14:24:09,740|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 14:24:11,978|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:24:12,750|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:24:12,752|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:24:12,753|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:24:13,128|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:24:13,129|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:24:13,130|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:24:13,478|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:24:13,480|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:24:13,480|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:24:13,834|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:24:13,835|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:24:13,866|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:24:14,232|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:24:14,233|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:24:14,234|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:24:14,579|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:24:14,580|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:24:14,580|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:24:14,929|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:24:14,931|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:24:14,931|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:24:15,566|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:24:15,568|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:24:30,101|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 400 Bad Request"]
[2025-08-19 14:24:30,108|(ERROR)| File: naukri | Message: 🔥 Error fetching Naukri jobs: Input is not valid: Field input.keyword must be string]
[2025-08-19 14:24:30,114|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 14:24:30,171|(ERROR)| File: job_recommendation | Message: Error while searching job from the naukri: 'ApifyApiError' object is not iterable]
[2025-08-19 14:26:38,980|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 14:26:41,479|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:26:42,933|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:26:42,937|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:26:42,938|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:26:43,674|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:26:43,675|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:26:43,676|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:26:44,279|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:26:44,281|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:26:44,282|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:26:44,884|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:26:44,886|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:26:44,927|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:26:45,542|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:26:45,545|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:26:45,547|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:26:46,290|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:26:46,297|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:26:46,300|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:26:46,968|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:26:46,970|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:26:46,970|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:26:47,529|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:26:47,533|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:27:12,536|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 14:27:15,908|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:27:16,965|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:27:16,967|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:27:16,968|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:27:17,507|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:27:17,509|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:27:17,510|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:27:18,085|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:27:18,087|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:27:18,088|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:27:18,657|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:27:18,660|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:27:18,696|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:27:19,334|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:27:19,336|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:27:19,336|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:27:19,908|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:27:19,910|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:27:19,910|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:27:20,492|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:27:20,493|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:27:20,494|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 14:27:20,986|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 14:27:20,988|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 14:28:17,157|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 201 Created"]
[2025-08-19 14:28:17,488|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:17,783|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-19 14:28:18,117|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:18,505|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-19 14:28:19,744|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:19,760|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-19 14:28:19,886|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-19 14:28:21,046|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:22,349|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:23,666|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:25,017|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:26,366|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:27,729|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:29,032|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/9kOJXZn1PxpqEyxXb "HTTP/1.1 200 OK"]
[2025-08-19 14:28:31,382|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/t468EfaE5efrRvLo9/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-19 14:28:31,681|(INFO)| File: naukri | Message: ✅ Retrieved 60 items from dataset: t468EfaE5efrRvLo9]
[2025-08-19 14:28:31,695|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:07:44,811|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 16:07:47,322|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:07:48,149|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:07:48,151|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:07:48,151|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:07:48,514|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:07:48,516|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:07:48,516|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:07:48,902|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:07:48,903|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:07:48,904|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:07:49,303|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:07:49,305|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:07:49,362|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:07:49,835|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:07:49,836|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:07:49,837|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:07:50,507|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:07:50,509|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:07:50,510|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:07:51,063|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:07:51,065|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:07:51,066|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:07:51,511|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:07:51,513|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:08:12,162|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 201 Created"]
[2025-08-19 16:08:13,779|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:14,138|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-19 16:08:14,460|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:14,769|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-19 16:08:16,094|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-19 16:08:16,139|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:16,154|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-19 16:08:17,528|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:18,846|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:20,167|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:21,521|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:22,849|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:24,172|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:25,485|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:26,865|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:28,180|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/ovUwe7BqoN0boMuNC "HTTP/1.1 200 OK"]
[2025-08-19 16:08:29,022|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/TzyxI6jv9GAoe4MzH/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-19 16:08:30,791|(INFO)| File: naukri | Message: ✅ Retrieved 70 items from dataset: TzyxI6jv9GAoe4MzH]
[2025-08-19 16:08:30,827|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:13:11,234|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 16:13:14,865|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:13:15,719|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:13:15,720|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:13:15,721|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:13:16,159|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:13:16,161|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:13:16,161|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:13:16,592|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:13:16,595|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:13:16,596|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:13:17,117|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:13:17,118|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:13:17,144|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:13:17,666|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:13:17,669|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:13:17,672|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:13:18,095|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:13:18,096|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:13:18,098|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:13:18,600|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:13:18,602|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:13:18,602|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:13:19,036|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:13:19,038|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:13:27,665|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 16:13:27,718|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:20:24,719|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 16:20:27,013|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:20:27,931|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:20:27,932|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:20:27,933|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:20:28,291|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:20:28,292|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:20:28,293|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:20:28,951|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:20:28,956|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:20:28,961|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:20:29,483|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:20:29,484|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:20:29,508|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:20:29,896|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:20:29,898|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:20:29,899|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:20:30,310|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:20:30,311|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:20:30,312|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:20:30,765|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:20:30,766|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:20:30,767|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 16:20:31,258|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 16:20:31,259|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 16:20:33,713|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 16:20:33,758|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:21:21,256|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 16:21:21,306|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:40:51,138|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 16:40:51,174|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:43:16,664|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 16:43:16,688|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:43:21,833|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 16:43:21,872|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:44:46,517|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 16:44:46,554|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:48:09,758|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 16:48:09,792|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 16:52:48,037|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 16:52:48,078|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:00:34,661|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:00:34,699|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:04:24,093|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:04:24,169|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:06:15,955|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:06:15,979|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:10:15,310|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:10:15,343|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:17:00,937|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:17:00,990|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:24:30,773|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:24:30,802|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:27:27,666|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:27:27,700|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:27:51,792|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:27:51,828|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:28:06,363|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:28:06,396|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:28:43,156|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:28:43,200|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:28:54,155|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:28:54,183|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:30:47,601|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:30:47,689|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:31:15,340|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:31:15,381|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:32:00,196|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:32:00,238|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:32:24,676|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:32:24,798|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:32:50,679|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:32:50,711|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:33:08,747|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:33:08,783|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:33:29,227|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:33:29,262|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:35:24,490|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:35:24,528|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:36:09,568|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:36:09,599|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:37:59,875|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:37:59,899|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:38:36,832|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:38:36,870|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:38:58,078|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:38:58,108|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:39:19,103|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:39:19,145|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:39:39,575|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:39:39,603|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:39:54,047|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:39:54,075|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:40:09,443|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:40:09,498|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:40:34,321|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:40:34,365|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:41:02,088|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:41:02,128|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:41:26,900|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:41:26,929|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:42:00,869|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:42:00,921|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:42:40,165|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:42:40,196|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:43:16,043|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:43:16,066|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:43:40,788|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:43:40,814|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:43:59,453|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:43:59,499|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:44:18,392|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:44:18,440|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:46:42,813|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:46:42,849|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:47:12,351|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:47:12,396|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:48:09,247|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:48:09,278|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:50:14,154|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:50:14,195|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:51:15,043|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:51:15,085|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:51:38,597|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:51:38,660|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:52:43,194|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:52:43,237|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:53:02,168|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:53:02,199|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:53:32,596|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:53:32,685|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:54:13,587|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:54:13,615|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:54:35,894|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:54:35,935|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:55:12,785|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:55:12,825|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:56:02,075|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:56:02,107|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:56:06,102|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:56:06,142|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:56:27,330|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:56:27,367|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:56:42,855|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:56:42,895|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:57:01,299|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:57:01,327|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:57:06,248|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:57:06,281|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 17:57:29,762|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 17:57:29,796|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 18:19:35,678|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 18:19:35,732|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 18:22:05,190|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 18:22:05,386|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 18:22:27,262|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 18:22:27,299|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 18:23:55,806|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 18:23:55,843|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 18:24:28,890|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 18:24:28,919|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 18:29:05,109|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 18:29:05,147|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 18:53:58,805|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 18:53:58,852|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 18:54:42,438|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 18:54:42,467|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 18:54:42,470|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: 'linkedin.html' not found in search path: 'app/templates']
[2025-08-19 18:55:34,325|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 18:55:37,616|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:55:38,578|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:55:38,580|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:55:38,580|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:55:38,975|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:55:38,976|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:55:38,977|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:55:39,347|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:55:39,349|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:55:39,349|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:55:39,928|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:55:39,930|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:55:39,989|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:55:40,556|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:55:40,558|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:55:40,558|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:55:41,077|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:55:41,079|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:55:41,079|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:55:41,491|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:55:41,492|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:55:41,493|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:55:41,907|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:55:41,908|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:55:42,112|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 18:55:42,152|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 18:55:59,213|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 18:56:02,400|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:03,515|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:03,517|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:03,518|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:03,988|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:03,989|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:03,989|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:04,491|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:04,493|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:04,494|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:04,928|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:04,929|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:04,951|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:05,466|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:05,467|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:05,468|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:06,433|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:06,435|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:06,436|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:07,061|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:07,063|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:07,064|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:07,998|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:08,000|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:19,731|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 18:56:23,558|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:24,710|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:24,712|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:24,713|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:25,365|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:25,368|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:25,369|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:26,069|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:26,074|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:26,077|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:27,018|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:27,020|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:27,070|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:28,051|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:28,055|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:28,058|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:28,724|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:28,726|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:28,727|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:29,422|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:29,424|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 18:56:29,426|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 18:56:30,119|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 18:56:30,121|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:01:29,164|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:01:29,227|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:05:09,676|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:05:09,711|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:05:23,405|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:05:23,433|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:07:20,512|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:07:20,549|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:07:51,488|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:07:51,522|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:15:53,659|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 19:15:58,965|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:03,315|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:03,319|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:03,320|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:03,924|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:03,928|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:03,929|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:04,561|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:04,565|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:04,567|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:05,174|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:05,177|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:05,244|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:06,375|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:06,378|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:06,379|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:07,005|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:07,009|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:07,011|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:07,781|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:07,783|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:07,784|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:08,420|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:08,422|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:17,481|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 19:16:20,093|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:21,674|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:21,676|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:21,677|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:22,127|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:22,129|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:22,129|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:22,533|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:22,534|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:22,535|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:22,905|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:22,906|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:22,928|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:23,316|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:23,317|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:23,318|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:23,689|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:23,690|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:23,691|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:24,054|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:24,055|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:24,056|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 19:16:24,430|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 19:16:24,432|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 19:16:46,713|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:16:46,848|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:19:32,604|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:19:32,633|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:22:43,129|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:22:43,166|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:22:47,341|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:22:47,376|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 19:22:55,077|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:22:55,106|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:37:05,152|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:37:05,189|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:37:45,008|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:37:45,046|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:38:20,313|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:38:20,339|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 19:38:35,023|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:38:35,055|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 19:41:05,751|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:41:05,791|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-19 19:41:12,868|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 19:41:12,900|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:42:19,768|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-19 20:42:22,594|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 20:42:23,414|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 20:42:23,416|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 20:42:23,416|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 20:42:23,774|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 20:42:23,776|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 20:42:23,776|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 20:42:24,135|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 20:42:24,136|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 20:42:24,137|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 20:42:24,505|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 20:42:24,506|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 20:42:24,562|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 20:42:24,915|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 20:42:24,917|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 20:42:24,917|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 20:42:25,270|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 20:42:25,271|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 20:42:25,272|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 20:42:25,624|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 20:42:25,626|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 20:42:25,626|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-19 20:42:26,107|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-19 20:42:26,108|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-19 20:42:43,011|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:42:43,073|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:43:56,321|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:43:56,350|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:45:36,862|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:45:36,944|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:46:12,245|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:46:12,279|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:46:23,464|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:46:23,512|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:47:58,721|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:47:58,749|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:48:29,519|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:48:29,553|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:53:26,514|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:53:26,550|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:53:48,065|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:53:48,164|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:54:50,919|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:54:50,943|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:55:20,597|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:55:20,622|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:55:50,162|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:55:50,195|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-19 20:56:01,100|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-19 20:56:01,127|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-20 14:54:16,615|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 14:54:22,047|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:54:24,693|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:54:24,696|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:54:24,696|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:54:25,336|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:54:25,338|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:54:25,338|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:54:26,012|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:54:26,015|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:54:26,016|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:54:26,596|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:54:26,597|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:54:26,653|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:54:27,321|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:54:27,325|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:54:27,326|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:54:28,026|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:54:28,032|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:54:28,042|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:54:28,757|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:54:28,759|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:54:28,760|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:54:29,257|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:54:29,259|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:55:05,708|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 14:55:09,668|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:55:11,117|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:55:11,124|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:55:11,129|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:55:12,257|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:55:12,266|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:55:12,272|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:55:13,623|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:55:13,626|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:55:13,628|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:55:14,263|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:55:14,266|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:55:14,327|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:55:15,316|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:55:15,324|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:55:15,332|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:55:16,498|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:55:16,504|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:55:16,505|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:55:17,190|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:55:17,191|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 14:55:17,192|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 14:55:18,187|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 14:55:18,191|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 15:04:36,517|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 15:04:38,402|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 15:04:39,132|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 15:04:39,134|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 15:04:39,135|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 15:04:39,798|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 15:04:39,800|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 15:04:39,801|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 15:04:40,194|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 15:04:40,195|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 15:04:40,196|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 15:04:40,549|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 15:04:40,550|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 15:04:40,575|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 15:04:40,945|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 15:04:40,947|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 15:04:40,948|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 15:04:41,442|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 15:04:41,444|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 15:04:41,444|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 15:04:41,841|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 15:04:41,842|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 15:04:41,843|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 15:04:42,206|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 15:04:42,207|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:18:15,539|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:18:18,235|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:18:19,018|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:18:19,020|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:18:19,021|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:18:19,378|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:18:19,380|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:18:19,381|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:18:19,743|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:18:19,744|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:18:19,745|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:18:20,101|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:18:20,102|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:18:20,168|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:18:20,623|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:18:20,625|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:18:20,625|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:18:21,093|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:18:21,094|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:18:21,095|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:18:21,457|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:18:21,458|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:18:21,459|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:18:21,863|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:18:21,864|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:29:16,056|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:29:18,941|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:29:19,778|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:29:19,780|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:29:19,781|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:29:20,171|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:29:20,172|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:29:20,173|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:29:20,534|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:29:20,535|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:29:20,536|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:29:20,897|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:29:20,899|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:29:20,947|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:29:21,389|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:29:21,391|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:29:21,392|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:29:21,804|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:29:21,806|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:29:21,806|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:29:22,241|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:29:22,242|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:29:22,243|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:29:22,616|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:29:22,617|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:27,523|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:35:31,162|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:35:33,567|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:35:33,570|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:33,572|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:35:34,245|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:35:34,247|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:34,248|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:35:35,040|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:35:35,043|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:35,045|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:35:36,025|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:35:36,027|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:36,110|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:35:36,965|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:35:36,966|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:36,967|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:35:37,852|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:35:37,854|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:37,854|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:35:38,515|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:35:38,519|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:38,521|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:35:39,230|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:35:39,232|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:52,328|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:35:58,140|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:35:59,450|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:35:59,454|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:35:59,455|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:00,114|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:00,116|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:00,117|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:00,775|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:00,778|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:00,779|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:01,457|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:01,462|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:01,520|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:02,166|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:02,175|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:02,186|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:03,230|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:03,232|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:03,233|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:03,868|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:03,869|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:03,870|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:04,475|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:04,477|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:15,234|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:36:21,481|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:23,269|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:23,276|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:23,277|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:24,159|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:24,163|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:24,166|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:25,025|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:25,027|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:25,027|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:25,729|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:25,731|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:25,776|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:27,011|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:27,022|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:27,023|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:27,789|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:27,791|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:27,792|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:28,434|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:28,436|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:28,436|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:29,850|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:29,853|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:41,966|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:36:44,822|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:45,785|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:45,787|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:45,788|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:46,349|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:46,350|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:46,351|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:46,989|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:46,993|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:46,994|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:47,426|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:47,427|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:47,455|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:48,031|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:48,034|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:48,035|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:48,635|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:48,637|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:48,638|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:49,272|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:49,273|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:36:49,274|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:36:49,726|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:36:49,728|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:24,062|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:37:26,809|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:27,708|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:27,710|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:27,710|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:28,225|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:28,227|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:28,227|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:28,628|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:28,630|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:28,631|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:29,130|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:29,132|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:29,198|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:29,920|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:29,922|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:29,923|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:30,851|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:30,855|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:30,858|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:32,700|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:32,705|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:32,706|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:33,436|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:33,438|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:51,209|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:37:55,185|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:56,404|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:56,408|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:56,409|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:57,045|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:57,048|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:57,049|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:57,649|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:57,651|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:57,652|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:58,391|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:58,395|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:58,443|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:37:59,442|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:37:59,446|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:37:59,446|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:00,046|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:00,047|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:00,048|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:00,640|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:00,642|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:00,644|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:01,128|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:01,129|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:07,637|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:38:09,722|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:10,424|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:10,426|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:10,427|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:10,770|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:10,772|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:10,772|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:11,126|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:11,127|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:11,128|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:11,465|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:11,467|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:11,489|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:11,856|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:11,857|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:11,858|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:12,215|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:12,217|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:12,217|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:12,556|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:12,557|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:38:12,558|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:38:12,913|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:38:12,914|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:28,339|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:40:31,677|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:33,012|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:33,015|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:33,016|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:33,677|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:33,680|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:33,681|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:35,024|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:35,026|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:35,027|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:35,747|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:35,749|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:35,790|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:36,464|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:36,465|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:36,466|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:37,100|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:37,102|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:37,103|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:38,464|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:38,479|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:38,489|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:39,537|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:39,539|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:47,123|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:40:49,897|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:51,222|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:51,224|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:51,225|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:51,668|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:51,670|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:51,670|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:52,054|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:52,056|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:52,057|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:52,574|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:52,576|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:52,600|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:53,186|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:53,189|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:53,191|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:53,714|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:53,717|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:53,718|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:54,160|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:54,162|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:40:54,162|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:40:54,596|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:40:54,597|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:42:21,351|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:42:24,379|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:42:25,116|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:42:25,118|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:42:25,119|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:42:25,537|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:42:25,540|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:42:25,541|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:42:25,982|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:42:25,983|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:42:25,984|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:42:26,431|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:42:26,433|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:42:26,473|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:42:27,019|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:42:27,022|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:42:27,024|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:42:27,413|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:42:27,415|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:42:27,417|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:42:27,806|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:42:27,807|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:42:27,808|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:42:28,159|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:42:28,160|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:11,051|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:45:15,505|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:17,506|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:17,510|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:17,512|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:18,152|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:18,153|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:18,154|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:18,865|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:18,868|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:18,870|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:19,531|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:19,533|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:19,578|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:20,294|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:20,295|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:20,296|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:20,996|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:20,998|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:20,999|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:21,640|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:21,641|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:21,642|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:22,354|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:22,356|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:34,817|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:45:38,948|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:39,905|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:39,907|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:39,908|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:40,313|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:40,314|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:40,315|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:40,851|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:40,853|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:40,855|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:42,000|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:42,005|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:42,058|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:42,518|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:42,520|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:42,520|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:43,008|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:43,010|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:43,010|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:43,563|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:43,566|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:43,568|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:44,112|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:44,114|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:53,544|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:45:56,116|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:57,298|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:57,302|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:57,304|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:57,928|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:57,932|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:57,933|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:58,574|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:58,579|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:58,582|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:59,047|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:59,048|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:59,077|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:45:59,561|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:45:59,565|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:45:59,566|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:00,249|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:00,254|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:00,255|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:01,066|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:01,068|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:01,069|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:01,659|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:01,662|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:23,663|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:46:27,325|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:28,741|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:28,751|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:28,752|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:29,424|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:29,427|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:29,428|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:30,230|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:30,234|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:30,235|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:31,374|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:31,377|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:31,423|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:32,095|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:32,098|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:32,100|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:32,944|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:32,946|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:32,947|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:33,809|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:33,811|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:33,812|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:34,853|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:34,855|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:51,216|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:46:54,635|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:55,933|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:55,935|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:55,936|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:56,581|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:56,583|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:56,585|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:57,245|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:57,247|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:57,248|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:58,911|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:58,915|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:58,966|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:46:59,652|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:46:59,654|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:46:59,654|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:00,350|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:00,353|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:00,354|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:01,025|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:01,027|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:01,028|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:01,668|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:01,670|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:10,676|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:47:14,189|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:15,478|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:15,482|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:15,483|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:16,488|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:16,490|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:16,491|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:17,030|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:17,031|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:17,032|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:17,473|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:17,475|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:17,498|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:17,922|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:17,924|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:17,924|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:18,342|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:18,343|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:18,344|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:18,741|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:18,743|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:47:18,743|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:47:19,138|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:47:19,140|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:49:57,946|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:50:01,291|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:03,091|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:03,094|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:03,095|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:03,742|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:03,744|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:03,746|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:04,356|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:04,359|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:04,360|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:04,991|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:04,993|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:05,030|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:05,725|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:05,728|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:05,730|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:06,456|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:06,458|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:06,459|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:07,636|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:07,639|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:07,640|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:08,274|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:08,276|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:19,442|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:50:21,592|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:22,353|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:22,355|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:22,356|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:22,741|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:22,742|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:22,742|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:23,102|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:23,103|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:23,104|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:23,436|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:23,437|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:23,462|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:23,840|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:23,842|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:23,842|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:24,199|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:24,201|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:24,201|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:24,580|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:24,581|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:50:24,581|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:50:24,930|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:50:24,931|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:51:24,352|(INFO)| File: ask_llm | Message: Running chain for suggestions.]
[2025-08-20 16:51:24,746|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Carefully analyze the following resume and identify **missing skills** that...]
[2025-08-20 16:51:24,762|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Analyze the following resume. Based on the candidate's skills, education, a...]
[2025-08-20 16:51:24,779|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Analyze the provided resume and identify actionable recommendations to enha...]
[2025-08-20 16:51:24,826|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.442006 seconds]
[2025-08-20 16:51:24,830|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.457564 seconds]
[2025-08-20 16:51:24,833|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.464758 seconds]
[2025-08-20 16:51:25,284|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.944614 seconds]
[2025-08-20 16:51:25,295|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.837507 seconds]
[2025-08-20 16:51:25,305|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.966886 seconds]
[2025-08-20 16:53:16,304|(INFO)| File: ask_llm | Message: Running chain for suggestions.]
[2025-08-20 16:53:16,330|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Analyze the following resume. Based on the candidate's skills, education, a...]
[2025-08-20 16:53:16,330|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Carefully analyze the following resume and identify **missing skills** that...]
[2025-08-20 16:53:16,367|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Analyze the provided resume and identify actionable recommendations to enha...]
[2025-08-20 16:53:24,543|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-20 16:53:33,306|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 502 Bad Gateway"]
[2025-08-20 16:53:33,308|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.409448 seconds]
[2025-08-20 16:53:34,127|(INFO)| File: _base_client | Message: Retrying request to /openai/v1/chat/completions in 0.478233 seconds]
[2025-08-20 16:53:37,506|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-20 16:53:37,530|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-20 16:53:37,554|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 16:59:25,198|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:59:27,722|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:28,737|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:28,739|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:28,740|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:29,258|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:29,260|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:29,261|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:29,803|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:29,805|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:29,806|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:30,390|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:30,392|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:30,431|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:31,066|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:31,070|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:31,071|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:31,658|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:31,660|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:31,660|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:32,186|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:32,189|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:32,191|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:32,885|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:32,887|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:44,005|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 16:59:48,881|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:50,222|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:50,226|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:50,227|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:50,951|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:50,954|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:50,956|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:51,771|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:51,773|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:51,774|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:53,212|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:53,230|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:53,490|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:54,655|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:54,659|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:54,660|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:55,327|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:55,330|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:55,332|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:55,979|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:55,982|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 16:59:55,984|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 16:59:56,765|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 16:59:56,769|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:08,263|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:00:12,127|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:13,403|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:13,405|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:13,407|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:14,098|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:14,100|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:14,101|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:14,814|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:14,816|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:14,817|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:15,457|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:15,459|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:15,504|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:16,161|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:16,163|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:16,163|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:16,805|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:16,808|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:16,809|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:17,452|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:17,453|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:17,454|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:18,090|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:18,092|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:29,539|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:00:32,623|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:33,373|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:33,374|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:33,375|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:33,710|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:33,712|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:33,712|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:34,062|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:34,064|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:34,064|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:34,481|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:34,482|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:34,508|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:34,944|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:34,945|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:34,946|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:35,382|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:35,383|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:35,384|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:35,762|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:35,763|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:35,764|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:36,114|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:36,116|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:43,804|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:00:49,362|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:50,531|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:50,534|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:50,536|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:51,155|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:51,156|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:51,157|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:51,568|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:51,571|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:51,572|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:52,089|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:52,090|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:52,116|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:52,521|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:52,523|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:52,523|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:52,892|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:52,894|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:52,895|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:53,372|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:53,373|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:00:53,374|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:00:53,731|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:00:53,733|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:00,025|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:01:02,219|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:03,455|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:03,466|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:03,476|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:04,505|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:04,508|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:04,510|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:05,631|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:05,633|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:05,634|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:06,282|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:06,285|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:06,330|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:06,914|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:06,916|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:06,916|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:07,541|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:07,543|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:07,545|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:08,103|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:08,104|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:08,106|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:08,542|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:08,544|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:15,903|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:01:18,289|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:19,130|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:19,132|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:19,133|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:19,534|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:19,537|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:19,538|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:19,951|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:19,953|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:19,954|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:20,388|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:20,390|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:20,416|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:20,801|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:20,803|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:20,803|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:21,214|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:21,215|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:21,216|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:21,590|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:21,591|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:01:21,592|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:01:22,029|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:01:22,031|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:03:39,359|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:03:41,403|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:03:42,131|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:03:42,133|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:03:42,134|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:03:42,522|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:03:42,524|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:03:42,524|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:03:42,893|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:03:42,894|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:03:42,895|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:03:43,249|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:03:43,250|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:03:43,283|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:03:43,684|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:03:43,687|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:03:43,688|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:03:44,119|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:03:44,121|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:03:44,122|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:03:44,499|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:03:44,500|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:03:44,501|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:03:44,902|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:03:44,903|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:07,567|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:04:10,093|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:10,798|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:10,800|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:10,800|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:11,155|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:11,157|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:11,158|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:11,531|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:11,532|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:11,533|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:11,913|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:11,915|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:11,953|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:12,431|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:12,433|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:12,436|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:12,893|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:12,895|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:12,896|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:13,253|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:13,254|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:13,255|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:13,656|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:13,658|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:20,388|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:04:22,686|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:23,444|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:23,446|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:23,447|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:23,790|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:23,792|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:23,792|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:24,154|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:24,156|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:24,156|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:24,585|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:24,586|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:24,607|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:24,996|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:24,998|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:24,999|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:25,396|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:25,398|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:25,398|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:25,742|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:25,743|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:04:25,744|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:04:26,099|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:04:26,100|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:05:30,850|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:05:33,727|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:05:34,904|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:05:34,906|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:05:34,908|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:05:35,543|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:05:35,547|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:05:35,550|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:05:36,222|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:05:36,232|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:05:36,238|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:05:36,782|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:05:36,783|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:05:36,820|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:05:37,249|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:05:37,251|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:05:37,252|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:05:38,055|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:05:38,057|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:05:38,058|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:05:38,560|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:05:38,562|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:05:38,563|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:05:38,988|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:05:38,989|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:06:47,956|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 17:08:10,041|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:08:13,141|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:08:14,530|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:08:14,533|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:08:14,534|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:08:15,145|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:08:15,147|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:08:15,148|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:08:15,760|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:08:15,762|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:08:15,762|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:08:16,363|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:08:16,364|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:08:16,420|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:08:17,064|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:08:17,065|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:08:17,066|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:08:17,709|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:08:17,711|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:08:17,711|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:08:18,309|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:08:18,311|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:08:18,311|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:08:19,099|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:08:19,101|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:08:38,296|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 17:09:01,847|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:09:04,066|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:09:05,112|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:09:05,116|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:09:05,118|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:09:05,685|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:09:05,687|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:09:05,687|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:09:06,028|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:09:06,030|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:09:06,030|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:09:06,387|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:09:06,388|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:09:06,417|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:09:06,776|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:09:06,777|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:09:06,778|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:09:07,233|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:09:07,234|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:09:07,235|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:09:08,135|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:09:08,138|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:09:08,140|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:09:08,575|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:09:08,576|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:16:32,532|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:16:36,619|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:16:37,914|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:16:37,917|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:16:37,918|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:16:38,556|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:16:38,558|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:16:38,560|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:16:39,199|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:16:39,201|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:16:39,202|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:16:39,829|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:16:39,831|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:16:55,512|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:17:00,715|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:03,631|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:03,657|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:03,660|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:04,364|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:04,366|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:04,366|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:05,014|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:05,016|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:05,017|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:05,652|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:05,654|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:19,997|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:17:22,036|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:22,980|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:22,983|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:22,983|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:23,714|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:23,716|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:23,716|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:24,286|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:24,288|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:24,289|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:25,027|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:25,037|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:38,015|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:17:41,436|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:42,687|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:42,690|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:42,691|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:43,326|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:43,330|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:43,331|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:43,972|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:43,973|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:17:43,974|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:17:44,631|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:17:44,634|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:02,259|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:18:05,433|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:06,724|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:06,727|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:06,728|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:07,389|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:07,392|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:07,393|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:08,652|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:08,653|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:08,654|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:09,314|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:09,316|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:09,357|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:10,018|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:10,020|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:10,021|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:10,707|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:10,708|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:10,709|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:11,377|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:11,379|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:11,380|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:12,048|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:12,051|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:27,481|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:18:30,802|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:32,054|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:32,056|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:32,057|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:33,463|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:33,465|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:33,466|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:34,425|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:34,432|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:34,433|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:36,043|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:36,048|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:46,921|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:18:49,111|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:49,970|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:49,972|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:49,973|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:50,375|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:50,376|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:50,376|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:50,763|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:50,765|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:18:50,766|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:18:51,263|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:18:51,265|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:20:52,003|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:20:55,644|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:20:56,916|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:20:56,919|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:20:56,920|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:20:57,278|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:20:57,280|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:20:57,280|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:20:57,628|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:20:57,630|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:20:57,630|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:20:57,996|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:20:57,997|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:20:58,050|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:20:58,591|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:20:58,592|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:20:58,593|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:20:59,059|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:20:59,060|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:20:59,060|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:20:59,436|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:20:59,438|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:20:59,438|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:20:59,932|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:20:59,934|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:22:33,985|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 17:22:33,986|(INFO)| File: helper | Message: Parsed using JSON]
[2025-08-20 17:35:16,419|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:35:20,931|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:22,062|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:22,066|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:22,067|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:22,754|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:22,758|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:22,762|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:23,437|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:23,439|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:23,440|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:24,071|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:24,074|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:24,117|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:25,258|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:25,261|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:25,262|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:25,872|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:25,875|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:25,876|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:26,508|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:26,510|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:26,512|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:27,166|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:27,168|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:37,458|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:35:41,419|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:42,855|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:42,858|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:42,859|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:43,578|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:43,580|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:43,581|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:44,405|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:44,408|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:44,409|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:45,073|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:45,075|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:45,111|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:45,806|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:45,810|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:45,811|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:46,468|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:46,470|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:46,471|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:47,022|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:47,024|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:35:47,024|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:35:47,625|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:35:47,628|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:36:33,048|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:36:37,205|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:36:38,465|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:36:38,468|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:36:38,469|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:36:39,111|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:36:39,113|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:36:39,113|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:36:39,807|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:36:39,810|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:36:39,811|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:36:40,449|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:36:40,451|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:36:40,496|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:36:41,105|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:36:41,107|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:36:41,108|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:36:41,734|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:36:41,736|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:36:41,736|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:36:42,419|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:36:42,421|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:36:42,422|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:36:43,151|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:36:43,153|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:36:55,401|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:36:59,166|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:37:00,616|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:37:00,618|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:37:00,619|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:37:01,117|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:37:01,118|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:37:01,119|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:37:01,676|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:37:01,679|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:37:01,683|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:37:02,178|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:37:02,180|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:37:02,202|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:37:02,587|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:37:02,589|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:37:02,590|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:37:03,037|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:37:03,040|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:37:03,040|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:37:03,623|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:37:03,627|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:37:03,630|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:37:04,070|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:37:04,072|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:37:41,532|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 17:38:10,615|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:38:14,466|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:38:15,926|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:38:15,936|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:38:15,944|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:38:17,005|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:38:17,008|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:38:17,009|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:38:17,642|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:38:17,645|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:38:17,646|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:38:18,361|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:38:18,370|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:38:18,489|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:38:19,614|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:38:19,616|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:38:19,618|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:38:20,822|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:38:20,825|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:38:20,827|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:38:21,513|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:38:21,515|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:38:21,516|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:38:22,383|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:38:22,385|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:09,834|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:39:13,163|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:14,826|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:14,830|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:14,834|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:15,536|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:15,539|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:15,541|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:16,392|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:16,399|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:16,410|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:18,026|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:18,028|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:18,066|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:18,709|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:18,712|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:18,713|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:19,952|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:19,953|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:19,954|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:20,833|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:20,841|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:20,847|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:21,745|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:21,747|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:35,354|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:39:37,830|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:38,921|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:38,923|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:38,924|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:39,760|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:39,764|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:39,769|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:40,568|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:40,573|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:40,578|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:41,363|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:41,365|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:41,409|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:42,059|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:42,061|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:42,062|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:42,697|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:42,700|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:42,701|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:43,252|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:43,254|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:43,254|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:43,838|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:43,842|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:52,160|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-20 17:39:54,609|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:55,426|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:55,428|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:55,428|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:55,842|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:55,843|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:55,845|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:56,254|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:56,255|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:56,256|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:56,689|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:56,691|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:56,715|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:57,155|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:57,157|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:57,157|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:57,550|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:57,552|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:57,552|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:57,955|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:57,957|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:39:57,957|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-20 17:39:58,468|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-20 17:39:58,470|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-20 17:49:04,205|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:01:09,990|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:04:05,266|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:06:51,713|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:10:32,170|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:14:57,520|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:24:48,115|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:32:34,444|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:34:29,007|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:37:24,353|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:38:31,340|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:41:04,911|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:41:52,733|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:45:30,433|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 18:56:57,148|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:02:06,059|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:06:52,863|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:07:59,806|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:12:51,061|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:13:38,918|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:14:46,415|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:16:11,600|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:16:18,974|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:16:51,320|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:18:06,187|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:18:34,115|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:20:29,321|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:28:10,910|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:33:31,613|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:38:36,552|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:40:37,372|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-20 19:40:39,777|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-20 19:40:58,748|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-20 19:40:59,343|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-20 19:44:41,928|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:44:58,532|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 19:46:14,859|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-20 19:46:17,420|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-20 19:46:41,218|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-20 19:46:42,989|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-20 19:46:49,759|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-20 19:46:50,362|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-20 20:21:39,123|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-20 20:21:50,592|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-20 20:21:51,140|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-21 13:17:15,457|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-21 13:17:18,265|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-21 13:17:19,106|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-21 13:17:19,109|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-21 13:17:19,112|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-21 13:17:19,629|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-21 13:17:19,630|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-21 13:17:19,631|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-21 13:17:20,006|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-21 13:17:20,008|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-21 13:17:20,008|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-21 13:17:20,366|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-21 13:17:20,367|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-21 13:17:20,423|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-21 13:17:20,796|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-21 13:17:20,797|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-21 13:17:20,798|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-21 13:17:21,320|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-21 13:17:21,321|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-21 13:17:21,322|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-21 13:17:21,775|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-21 13:17:21,776|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-21 13:17:21,777|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-21 13:17:22,171|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-21 13:17:22,172|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-21 13:18:03,278|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-21 13:18:40,863|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-21 13:18:43,243|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-21 13:31:22,435|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-21 16:01:50,199|(INFO)| File: jobs_cache | Message: Job response cached for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 16:01:50,233|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 19:32:12,698|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 19:34:42,132|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 19:34:42,161|(INFO)| File: suggestions_cache | Message: No cached suggestions found for file hash: 891114b445...]
[2025-08-21 19:34:42,165|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for file hash: 891114b445...]
[2025-08-21 19:36:17,115|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 19:36:17,122|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for file hash: 891114b445...]
[2025-08-21 19:47:35,479|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 19:47:35,507|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for file hash: 891114b445...]
[2025-08-21 19:47:35,511|(INFO)| File: keywords_cache | Message: No cached keywords found for file hash: 891114b445...]
[2025-08-21 19:47:35,519|(INFO)| File: keywords_cache | Message: Keywords saved to cache for file hash: 891114b445...]
[2025-08-21 19:47:35,527|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for file hash: 891114b445...]
[2025-08-21 20:06:18,565|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 20:06:18,574|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for file hash: 891114b445...]
[2025-08-21 20:06:18,579|(INFO)| File: keywords_cache | Message: No cached keywords found for file hash: 891114b445...]
[2025-08-21 20:06:18,584|(INFO)| File: keywords_cache | Message: Keywords saved to cache for file hash: 891114b445...]
[2025-08-21 20:06:18,589|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for file hash: 891114b445...]
[2025-08-21 20:06:18,616|(INFO)| File: resume_cache | Message: No cached resume found for file hash: 7f03bf2bee...]
[2025-08-21 20:06:18,623|(INFO)| File: resume_cache | Message: Resume saved to cache for file hash: 7f03bf2bee...]
[2025-08-21 20:07:54,758|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 20:07:54,769|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for file hash: 891114b445...]
[2025-08-21 20:07:54,781|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for file hash: 891114b445...]
[2025-08-21 20:08:41,708|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 20:08:41,710|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for file hash: 891114b445...]
[2025-08-21 20:08:41,712|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for file hash: 891114b445...]
[2025-08-21 20:09:08,425|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 20:09:08,428|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for file hash: 891114b445...]
[2025-08-21 20:09:08,430|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for file hash: 891114b445...]
[2025-08-21 20:09:08,433|(INFO)| File: resume_cache | Message: Cached resume retrieved for file hash: 7f03bf2bee...]
[2025-08-21 20:10:29,482|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 20:10:29,485|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for file hash: 891114b445...]
[2025-08-21 20:10:29,487|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for file hash: 891114b445...]
[2025-08-21 20:10:29,490|(INFO)| File: resume_cache | Message: Cached resume retrieved for file hash: 7f03bf2bee...]
[2025-08-21 20:13:07,659|(INFO)| File: resume_cache | Message: Cached resume retrieved for file hash: 7f03bf2bee...]
[2025-08-21 20:14:19,076|(INFO)| File: resume_cache | Message: Cached resume retrieved for file hash: 7f03bf2bee...]
[2025-08-21 20:17:11,655|(INFO)| File: resume_cache | Message: Cached resume retrieved for file hash: 7f03bf2bee...]
[2025-08-21 20:18:46,364|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/search?keywords=python&location=india]
[2025-08-21 20:18:46,369|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for file hash: 891114b445...]
[2025-08-21 20:18:46,372|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for file hash: 891114b445...]
[2025-08-21 20:18:46,375|(INFO)| File: resume_cache | Message: Cached resume retrieved for file hash: 7f03bf2bee...]
[2025-08-21 20:23:28,550|(INFO)| File: jobs_cache | Message: No cached job response found for URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 20:23:28,575|(INFO)| File: jobs_cache | Message: Job response cached for URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 20:23:28,578|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 20:23:28,581|(INFO)| File: jobs_cache | Message: No cached job response found for URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 20:23:28,586|(INFO)| File: jobs_cache | Message: Job response cached for URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 20:23:28,589|(INFO)| File: jobs_cache | Message: Cached job response retrieved for URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:17:22,005|(INFO)| File: jobs_cache | Message: No cached job response found for session:ab312a77-51f0-49df-abd9-474474108132 & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:17:22,040|(INFO)| File: jobs_cache | Message: Job response cached for session:ab312a77-51f0-49df-abd9-474474108132 &  URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:17:22,043|(INFO)| File: jobs_cache | Message: No cached job response found for session:ab312a77-51f0-49df-abd9-474474108132 & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:17:22,045|(INFO)| File: jobs_cache | Message: No cached job response found for session:ab312a77-51f0-49df-abd9-474474108132 & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:17:22,048|(INFO)| File: jobs_cache | Message: Job response cached for session:ab312a77-51f0-49df-abd9-474474108132 &  URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:17:22,050|(INFO)| File: jobs_cache | Message: No cached job response found for session:ab312a77-51f0-49df-abd9-474474108132 & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:21:57,618|(INFO)| File: jobs_cache | Message: No cached job response found for session:fc84c3ce-fa04-46f1-99f9-a71aea9ae6e7 & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:21:57,620|(INFO)| File: jobs_cache | Message: Job response cached for session:fc84c3ce-fa04-46f1-99f9-a71aea9ae6e7 &  URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:21:57,623|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:fc84c3ce-fa04-46f1-99f9-a71aea9ae6e7 & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:21:57,625|(INFO)| File: jobs_cache | Message: No cached job response found for session:fc84c3ce-fa04-46f1-99f9-a71aea9ae6e7 & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:21:57,627|(INFO)| File: jobs_cache | Message: Job response cached for session:fc84c3ce-fa04-46f1-99f9-a71aea9ae6e7 &  URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:21:57,629|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:fc84c3ce-fa04-46f1-99f9-a71aea9ae6e7 & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:47:33,770|(INFO)| File: jobs_cache | Message: No cached job response found for session:ddd51ca5-1612-44f1-8945-9305211cb06e & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:47:33,772|(INFO)| File: jobs_cache | Message: Job response cached for session:ddd51ca5-1612-44f1-8945-9305211cb06e &  URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:47:33,775|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:ddd51ca5-1612-44f1-8945-9305211cb06e & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:47:33,778|(INFO)| File: jobs_cache | Message: No cached job response found for session:ddd51ca5-1612-44f1-8945-9305211cb06e & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:47:33,780|(INFO)| File: jobs_cache | Message: Job response cached for session:ddd51ca5-1612-44f1-8945-9305211cb06e &  URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:47:33,786|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:ddd51ca5-1612-44f1-8945-9305211cb06e & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:51:07,140|(INFO)| File: jobs_cache | Message: No cached job response found for session:7df67323-c526-41b1-8011-318da6b878f1 & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:51:07,145|(INFO)| File: jobs_cache | Message: Job response cached for session:7df67323-c526-41b1-8011-318da6b878f1 &  URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:51:07,147|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:7df67323-c526-41b1-8011-318da6b878f1 & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:51:07,149|(INFO)| File: jobs_cache | Message: No cached job response found for session:7df67323-c526-41b1-8011-318da6b878f1 & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:51:07,153|(INFO)| File: jobs_cache | Message: Job response cached for session:7df67323-c526-41b1-8011-318da6b878f1 &  URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:51:07,158|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:7df67323-c526-41b1-8011-318da6b878f1 & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:51:07,161|(INFO)| File: suggestions_cache | Message: No cached suggestions found for session:7df67323-c526-41b1-8011-318da6b878f1 & file hash: 891114b445...]
[2025-08-21 22:52:15,803|(INFO)| File: jobs_cache | Message: No cached job response found for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:52:15,806|(INFO)| File: jobs_cache | Message: Job response cached for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca &  URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:52:15,808|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:52:15,810|(INFO)| File: jobs_cache | Message: No cached job response found for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:52:15,812|(INFO)| File: jobs_cache | Message: Job response cached for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca &  URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:52:15,814|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:52:15,816|(INFO)| File: suggestions_cache | Message: No cached suggestions found for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & file hash: 891114b445...]
[2025-08-21 22:52:15,820|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & file hash: 891114b445...]
[2025-08-21 22:52:15,822|(INFO)| File: keywords_cache | Message: No cached keywords found for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & file hash: 891114b445...]
[2025-08-21 22:52:15,824|(INFO)| File: keywords_cache | Message: Keywords saved to cache for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & file hash: 891114b445...]
[2025-08-21 22:52:15,826|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & file hash: 891114b445...]
[2025-08-21 22:52:15,829|(INFO)| File: resume_cache | Message: No cached resume found for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & file hash: 7f03bf2bee...]
[2025-08-21 22:52:15,831|(INFO)| File: resume_cache | Message: Resume saved to cache for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & file hash: 7f03bf2bee...]
[2025-08-21 22:52:15,834|(INFO)| File: resume_cache | Message: Cached resume retrieved for session:f1feae9b-78df-4eea-a0a5-56efeb5073ca & file hash: 7f03bf2bee...]
[2025-08-21 22:53:10,173|(INFO)| File: jobs_cache | Message: No cached job response found for session:24ae791f-c6d6-45fb-840c-427ea6375813 & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:53:10,178|(INFO)| File: jobs_cache | Message: Job response cached for session:24ae791f-c6d6-45fb-840c-427ea6375813 &  URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:53:10,183|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:24ae791f-c6d6-45fb-840c-427ea6375813 & URL: https://api.jobs.com/linkedin/search?keywords=python&location=india]
[2025-08-21 22:53:10,186|(INFO)| File: jobs_cache | Message: No cached job response found for session:24ae791f-c6d6-45fb-840c-427ea6375813 & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:53:10,190|(INFO)| File: jobs_cache | Message: Job response cached for session:24ae791f-c6d6-45fb-840c-427ea6375813 &  URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:53:10,194|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:24ae791f-c6d6-45fb-840c-427ea6375813 & URL: https://api.jobs.com/naukri/search?keywords=python&location=india]
[2025-08-21 22:53:10,196|(INFO)| File: suggestions_cache | Message: No cached suggestions found for session:24ae791f-c6d6-45fb-840c-427ea6375813 & file hash: 891114b445...]
[2025-08-21 22:53:10,200|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for session:24ae791f-c6d6-45fb-840c-427ea6375813 & file hash: 891114b445...]
[2025-08-21 22:53:10,202|(INFO)| File: keywords_cache | Message: No cached keywords found for session:24ae791f-c6d6-45fb-840c-427ea6375813 & file hash: 891114b445...]
[2025-08-21 22:53:10,205|(INFO)| File: keywords_cache | Message: Keywords saved to cache for session:24ae791f-c6d6-45fb-840c-427ea6375813 & file hash: 891114b445...]
[2025-08-21 22:53:10,207|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:24ae791f-c6d6-45fb-840c-427ea6375813 & file hash: 891114b445...]
[2025-08-21 22:53:10,209|(INFO)| File: resume_cache | Message: No cached resume found for session:24ae791f-c6d6-45fb-840c-427ea6375813 & file hash: 7f03bf2bee...]
[2025-08-21 22:53:10,212|(INFO)| File: resume_cache | Message: Resume saved to cache for session:24ae791f-c6d6-45fb-840c-427ea6375813 & file hash: 7f03bf2bee...]
[2025-08-21 22:53:10,214|(INFO)| File: resume_cache | Message: Cached resume retrieved for session:24ae791f-c6d6-45fb-840c-427ea6375813 & file hash: 7f03bf2bee...]
[2025-08-22 14:25:31,897|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:30:22,418|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:31:14,719|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:31:24,162|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:31:28,302|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:31:28,332|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:31:28,347|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:31:30,084|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:31:30,101|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:31:30,106|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:31:31,657|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:31:31,671|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:31:31,684|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:31:33,107|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:31:33,113|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:31:33,376|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:31:35,089|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:31:35,100|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:31:35,114|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:31:36,509|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:31:36,512|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:31:36,513|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:31:37,873|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:31:37,886|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:31:37,887|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:31:39,630|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:31:39,632|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:32:56,120|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:33:06,664|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:33:10,812|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:33:10,814|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:33:10,821|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:33:12,475|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:33:12,479|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:33:12,487|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:33:14,227|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:33:14,231|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:33:14,240|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:33:16,198|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:33:16,210|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:33:16,307|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:33:18,019|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:33:18,022|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:33:18,030|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:33:19,269|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:33:19,282|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:33:19,284|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:33:20,992|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:33:20,997|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:33:21,008|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:33:22,196|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:33:22,199|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:33:24,453|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:33:24,473|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:34:10,602|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 400: Session ID is required in headers]
[2025-08-22 14:36:01,644|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 14:36:01,649|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 14:36:28,610|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:36:33,625|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:36:34,830|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:36:34,833|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:36:34,834|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:36:35,603|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:36:35,606|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:36:35,607|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:36:36,373|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:36:36,380|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:36:36,383|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:36:37,181|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:36:37,183|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:36:37,243|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:36:38,188|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:36:38,193|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:36:38,195|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:36:39,188|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:36:39,190|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:36:39,190|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:36:40,114|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:36:40,117|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:36:40,118|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:36:41,070|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:36:41,075|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:36:41,837|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:36:41,840|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:37:10,386|(INFO)| File: keywords_cache | Message: No cached keywords found for session:123 & file hash: 20cdc289a1...]
[2025-08-22 14:37:10,389|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 14:37:10,389|(INFO)| File: job_recommendation | Message: 🔍 No cache found, saving keywords...]
[2025-08-22 14:37:10,397|(INFO)| File: keywords_cache | Message: Keywords saved to cache for session:123 & file hash: 20cdc289a1...]
[2025-08-22 14:37:10,397|(INFO)| File: job_recommendation | Message: ✅ Saved keywords to cache]
[2025-08-22 14:37:10,398|(ERROR)| File: job_recommendation | Message: Error while generating keywords: Object of type Keywords is not JSON serializable]
[2025-08-22 14:37:42,817|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 14:37:42,840|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 14:38:09,456|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:38:15,237|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:18,224|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:18,227|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:18,228|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:19,726|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:19,728|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:19,728|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:21,827|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:21,852|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:21,861|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:23,578|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:23,604|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:23,818|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:25,652|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:25,654|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:25,662|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:27,208|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:27,224|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:27,226|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:28,768|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:28,771|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:28,778|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:30,567|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:30,571|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:31,651|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:38:31,660|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:38:49,983|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:38:53,440|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:54,654|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:54,656|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:54,658|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:55,139|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:55,140|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:55,141|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:55,598|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:55,599|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:55,600|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:56,110|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:56,111|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:56,149|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:56,638|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:56,640|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:56,641|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:57,084|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:57,086|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:57,087|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:57,967|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:57,970|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:57,970|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:38:58,899|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:38:58,902|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:38:59,407|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:38:59,410|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:39:06,435|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:123 & file hash: 20cdc289a1...]
[2025-08-22 14:39:45,960|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:123 & file hash: 20cdc289a1...]
[2025-08-22 14:40:05,790|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 14:40:05,798|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 14:40:24,724|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:40:26,715|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:27,546|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:27,549|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:27,551|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:28,070|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:28,073|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:28,073|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:28,537|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:28,541|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:28,542|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:29,069|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:29,072|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:29,111|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:29,907|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:29,910|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:29,910|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:30,431|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:30,434|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:30,435|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:31,091|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:31,093|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:31,094|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:31,476|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:31,478|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:31,703|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:40:31,705|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:40:40,960|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:40:45,680|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:47,322|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:47,325|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:47,326|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:48,328|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:48,330|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:48,332|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:49,185|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:49,187|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:49,189|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:50,031|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:50,035|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:50,072|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:50,867|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:50,871|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:50,872|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:52,001|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:52,002|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:52,003|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:52,836|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:52,839|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:52,841|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:40:53,847|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:40:53,850|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:40:54,254|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:40:54,257|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:42:06,989|(INFO)| File: keywords_cache | Message: No cached keywords found for session:1234 & file hash: 20cdc289a1...]
[2025-08-22 14:42:06,991|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 14:42:06,991|(INFO)| File: job_recommendation | Message: 🔍 No cache found, saving keywords...]
[2025-08-22 14:42:06,994|(INFO)| File: keywords_cache | Message: Keywords saved to cache for session:1234 & file hash: 20cdc289a1...]
[2025-08-22 14:42:06,994|(INFO)| File: job_recommendation | Message: ✅ Saved keywords to cache]
[2025-08-22 14:42:47,296|(INFO)| File: jobs_cache | Message: No cached job response found for session:1234 & URL: /job-recommendation/linkedin?keywords=&location=Neemuch]
[2025-08-22 14:42:47,551|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 14:42:49,935|(INFO)| File: jobs_cache | Message: Job response cached for session:1234 &  URL: /job-recommendation/linkedin?keywords=&location=Neemuch]
[2025-08-22 14:42:49,935|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-22 14:43:31,468|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:1234 & file hash: 20cdc289a1...]
[2025-08-22 14:43:45,417|(INFO)| File: jobs_cache | Message: No cached job response found for session:1234 & URL: /job-recommendation/naukri?keywords=&location=Neemuch]
[2025-08-22 14:43:45,579|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 14:43:46,254|(INFO)| File: jobs_cache | Message: Job response cached for session:1234 &  URL: /job-recommendation/naukri?keywords=&location=Neemuch]
[2025-08-22 14:43:46,255|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-22 14:44:07,730|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:1234 & file hash: 20cdc289a1...]
[2025-08-22 14:44:15,391|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-22 14:44:31,313|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 14:44:31,314|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 14:46:02,714|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:46:07,061|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:46:09,034|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:46:09,051|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:46:09,054|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:46:10,068|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:46:10,071|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:46:10,072|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:46:11,164|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:46:11,174|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:46:11,178|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:46:12,218|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:46:12,229|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:46:12,270|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:46:13,102|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:46:13,106|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:46:13,107|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:46:14,054|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:46:14,057|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:46:14,060|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:46:15,156|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:46:15,158|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:46:15,159|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:46:16,331|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:46:16,333|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:46:17,270|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:46:17,273|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:47:12,626|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:1234 & file hash: 20cdc289a1...]
[2025-08-22 14:47:22,243|(INFO)| File: jobs_cache | Message: No cached job response found for session:1234 & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=Neemuch]
[2025-08-22 14:47:22,512|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 14:47:24,505|(INFO)| File: jobs_cache | Message: Job response cached for session:1234 &  URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=Neemuch]
[2025-08-22 14:47:24,506|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-22 14:47:52,331|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:1234 & file hash: 20cdc289a1...]
[2025-08-22 14:47:58,021|(INFO)| File: jobs_cache | Message: No cached job response found for session:1234 & URL: /job-recommendation/naukri?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=Neemuch]
[2025-08-22 14:47:58,147|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 14:47:58,805|(INFO)| File: jobs_cache | Message: Job response cached for session:1234 &  URL: /job-recommendation/naukri?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=Neemuch]
[2025-08-22 14:47:58,806|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-22 14:50:57,181|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 14:50:57,206|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 14:51:23,232|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:51:28,124|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:30,818|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:30,824|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:30,826|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:32,296|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:32,304|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:32,308|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:33,419|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:33,421|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:33,421|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:33,989|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:33,990|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:34,039|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:34,572|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:34,574|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:34,574|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:35,266|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:35,269|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:35,271|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:35,940|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:35,945|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:35,950|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:37,037|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:37,039|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:37,733|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:51:37,737|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:51:49,738|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:51:54,177|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:55,484|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:55,486|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:55,487|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:56,110|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:56,112|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:56,113|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:56,729|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:56,731|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:56,732|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:57,359|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:57,360|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:57,397|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:58,006|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:58,007|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:58,008|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:58,626|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:58,629|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:58,629|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:51:59,450|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:51:59,453|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:51:59,456|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:52:00,142|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:52:00,144|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:52:00,510|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:52:00,512|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:52:12,555|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:52:16,372|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:52:17,682|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:52:17,691|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:52:17,696|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:52:18,372|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:52:18,378|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:52:18,379|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:52:19,191|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:52:19,194|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:52:19,195|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:52:19,838|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:52:19,842|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:52:19,946|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:52:20,786|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:52:20,792|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:52:20,803|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:52:21,678|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:52:21,684|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:52:21,690|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:52:22,475|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:52:22,488|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:52:22,491|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:52:23,400|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:52:23,403|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:52:23,843|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:52:23,846|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:53:25,642|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 14:53:25,643|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 14:53:39,741|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:53:44,693|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:53:46,556|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:53:46,561|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:53:46,562|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:53:47,207|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:53:47,211|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:53:47,212|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:53:48,126|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:53:48,130|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:53:48,133|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:53:48,836|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:53:48,838|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:53:48,873|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:53:49,397|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:53:49,398|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:53:49,400|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:53:49,842|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:53:49,844|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:53:49,845|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:53:50,355|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:53:50,356|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:53:50,357|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:53:50,956|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:53:50,958|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:53:51,275|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:53:51,278|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:54:06,057|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:54:10,401|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:54:11,724|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:54:11,727|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:54:11,728|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:54:12,875|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:54:12,877|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:54:12,877|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:54:13,746|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:54:13,748|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:54:13,758|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:54:14,911|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:54:14,915|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:54:35,517|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:54:41,589|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:54:44,134|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:54:44,144|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:54:44,145|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:54:45,487|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:54:45,489|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:54:45,490|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:54:46,364|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:54:46,366|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:54:46,368|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:54:47,327|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:54:47,329|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:17,090|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:55:25,477|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:27,567|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:27,580|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:27,594|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:28,773|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:28,777|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:28,778|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:29,703|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:29,707|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:29,711|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:30,799|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:30,801|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:30,874|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:31,929|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:31,931|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:31,932|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:32,977|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:32,980|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:32,980|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:34,433|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:34,437|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:34,444|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:35,235|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:35,237|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:35,894|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:55:35,896|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:55:53,753|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:55:57,118|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:58,249|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:58,251|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:58,252|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:58,633|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:58,635|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:58,635|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:55:59,288|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:55:59,290|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:55:59,292|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:00,221|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:00,223|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:00,266|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:00,943|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:00,945|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:00,946|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:01,542|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:01,545|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:01,546|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:02,018|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:02,019|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:02,020|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:02,467|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:02,469|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:02,743|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:56:02,745|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:56:14,729|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 14:56:14,730|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 14:56:29,252|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:56:35,006|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:37,380|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:37,383|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:37,385|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:38,490|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:38,499|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:38,511|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:39,621|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:39,623|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:39,624|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:40,438|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:40,442|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:40,490|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:41,198|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:41,199|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:41,200|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:41,963|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:41,968|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:41,971|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:43,657|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:43,661|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:43,666|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:56:45,186|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:56:45,189|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:56:45,758|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:56:45,762|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:57:07,106|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:57:13,734|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:57:16,176|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:57:16,186|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:57:16,189|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:57:17,050|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:57:17,052|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:57:17,053|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:57:18,065|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:57:18,069|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:57:18,070|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:57:19,725|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:57:19,732|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:57:46,119|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:57:51,303|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:57:53,765|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:57:53,768|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:57:53,769|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:57:54,712|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:57:54,715|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:57:54,716|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:57:56,092|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:57:56,094|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:57:56,095|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:57:58,638|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:57:58,640|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:57:58,783|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:57:59,717|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:57:59,722|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:57:59,725|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:00,658|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:00,668|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:00,670|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:03,514|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:03,517|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:03,518|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:05,466|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:05,468|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:06,125|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:58:06,135|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:58:28,538|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:58:35,917|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:37,966|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:37,969|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:37,970|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:38,939|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:38,942|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:38,944|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:40,053|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:40,060|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:40,063|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:41,348|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:41,350|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:41,408|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:42,204|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:42,209|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:42,210|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:43,222|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:43,227|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:43,228|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:44,737|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:44,739|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:44,747|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:58:45,654|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:58:45,671|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:58:46,190|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:58:46,193|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:59:06,507|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:59:12,905|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:15,597|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:15,603|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:15,606|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:16,563|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:16,565|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:16,566|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:17,629|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:17,639|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:17,643|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:18,768|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:18,770|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:18,994|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:20,544|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:20,546|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:20,551|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:21,482|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:21,486|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:21,491|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:22,468|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:22,469|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:22,470|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:23,750|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:23,753|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:24,613|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 14:59:24,615|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 14:59:41,295|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 14:59:49,470|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:54,717|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:54,719|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:54,721|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:57,840|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:57,852|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:57,854|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 14:59:59,581|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 14:59:59,583|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 14:59:59,585|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:00,931|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:00,941|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:01,033|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:02,736|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:02,761|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:02,765|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:04,530|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:04,535|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:04,545|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:05,902|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:05,904|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:05,906|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:07,799|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:07,801|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:08,677|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 15:00:08,680|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 15:00:32,582|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 15:00:36,874|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:38,231|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:38,234|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:38,235|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:39,060|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:39,062|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:39,063|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:40,943|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:40,946|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:40,947|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:42,093|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:42,098|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:42,202|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:43,272|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:43,275|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:43,276|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:44,087|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:44,088|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:44,089|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:45,834|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:45,843|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:45,850|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:00:46,942|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:00:46,944|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:00:47,628|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 15:00:47,634|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 15:01:27,079|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:1234 & file hash: 20cdc289a1...]
[2025-08-22 15:01:33,249|(INFO)| File: jobs_cache | Message: No cached job response found for session:1234 & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 15:01:33,507|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 15:01:35,733|(INFO)| File: jobs_cache | Message: Job response cached for session:1234 &  URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 15:01:35,734|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-22 15:01:52,699|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:1234 & file hash: 20cdc289a1...]
[2025-08-22 15:02:06,213|(INFO)| File: suggestions_cache | Message: No cached suggestions found for session:1234 & file hash: 20cdc289a1...]
[2025-08-22 15:02:06,214|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-22 15:02:06,231|(INFO)| File: suggestions | Message: 🔍 No cache found, saving suggestions...]
[2025-08-22 15:02:06,234|(INFO)| File: suggestions | Message: ✅ Saved suggestions to cache]
[2025-08-22 15:02:48,670|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 15:02:48,676|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 15:23:00,433|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 15:23:02,644|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:23:03,474|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:23:03,476|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:23:03,477|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:23:03,964|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:23:03,965|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:23:03,966|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:23:04,371|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:23:04,374|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:23:04,376|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:23:04,784|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:23:04,785|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:23:04,834|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:23:05,309|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:23:05,311|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:23:05,312|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:23:05,850|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:23:05,852|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:23:05,853|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:23:06,254|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:23:06,256|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:23:06,257|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:23:06,666|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:23:06,668|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:23:06,919|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 15:23:06,921|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 15:23:28,156|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:23:28,157|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 15:23:28,158|(INFO)| File: job_recommendation | Message: 🔍 No cache found, saving keywords...]
[2025-08-22 15:23:28,161|(INFO)| File: keywords_cache | Message: Keywords saved to cache for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:23:28,161|(INFO)| File: job_recommendation | Message: ✅ Saved keywords to cache]
[2025-08-22 15:23:43,217|(INFO)| File: jobs_cache | Message: No cached job response found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 15:23:43,626|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 15:23:46,425|(INFO)| File: jobs_cache | Message: Job response cached for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe &  URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 15:23:46,426|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-22 15:24:02,545|(INFO)| File: jobs_cache | Message: No cached job response found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/naukri?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 15:24:02,732|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 15:24:03,502|(INFO)| File: jobs_cache | Message: Job response cached for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe &  URL: /job-recommendation/naukri?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 15:24:03,503|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-22 15:24:38,463|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:24:47,159|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 15:24:47,160|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 15:25:19,104|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 15:25:21,700|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:25:22,592|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:25:22,595|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:25:22,597|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:25:22,995|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:25:22,996|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:25:22,997|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:25:23,400|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:25:23,401|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:25:23,402|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:25:23,986|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:25:23,993|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:25:24,089|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:25:24,836|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:25:24,837|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:25:24,838|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:25:25,205|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:25:25,206|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:25:25,207|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:25:25,625|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:25:25,626|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:25:25,627|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:25:26,081|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:25:26,083|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:25:26,349|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 15:25:26,351|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 15:25:43,242|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:25:52,650|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/naukri?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 15:26:11,459|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:26:16,565|(INFO)| File: suggestions_cache | Message: No cached suggestions found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:26:16,565|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-22 15:26:16,583|(INFO)| File: suggestions | Message: 🔍 No cache found, saving suggestions...]
[2025-08-22 15:26:16,586|(INFO)| File: suggestions | Message: ✅ Saved suggestions to cache]
[2025-08-22 15:27:48,506|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 15:27:48,507|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 15:32:34,799|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 15:32:38,897|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:32:40,704|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:32:40,707|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:32:40,709|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:32:41,477|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:32:41,480|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:32:41,485|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:32:42,124|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:32:42,126|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:32:42,127|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:32:42,943|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:32:42,946|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:32:42,988|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:32:43,626|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:32:43,628|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:32:43,629|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:32:44,296|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:32:44,299|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:32:44,299|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:32:44,930|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:32:44,933|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:32:44,934|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 15:32:45,620|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 15:32:45,624|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 15:32:46,074|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 15:32:46,077|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 15:33:14,987|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:33:31,811|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:36:05,421|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:36:17,410|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:38:55,307|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:39:13,412|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 15:57:55,232|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:06:48,314|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:07:02,363|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:07:02,764|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:11:02,335|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:12:10,162|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:12:10,581|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:13:51,072|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:14:16,500|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:14:51,737|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:14:52,132|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:15:53,195|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:16:26,935|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:16:27,437|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:21:05,238|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:22:34,038|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:23:13,127|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:23:13,378|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:39:27,456|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:40:56,337|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:40:56,655|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:44:37,541|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 16:45:14,363|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:45:14,648|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:46:20,486|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/naukri?keywords=Software Engineer,Data Scientist,Machine Learning Engineer,Full Stack Developer,DevOps Engineer&location=India]
[2025-08-22 16:47:44,157|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 16:47:44,160|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:07:18,929|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:07:28,126|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:07:30,931|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:07:30,934|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:07:30,935|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:07:32,063|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:07:32,069|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:07:32,073|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:07:33,345|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:07:33,346|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:07:33,347|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:07:34,501|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:07:34,503|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:07:34,562|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:07:35,464|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:07:35,493|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:07:35,520|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:07:37,121|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:07:37,123|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:07:37,124|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:07:38,196|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:07:38,208|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:07:38,221|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:07:39,252|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:07:39,253|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:07:39,855|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:07:39,858|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:07:59,172|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:08:01,946|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:08:03,016|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:08:03,018|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:08:03,019|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:08:03,652|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:08:03,654|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:08:03,655|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:08:04,132|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:08:04,134|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:08:04,135|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:08:04,669|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:08:04,673|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:08:04,711|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:08:05,234|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:08:05,236|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:08:05,237|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:08:05,813|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:08:05,814|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:08:05,815|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:08:06,314|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:08:06,317|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:08:06,319|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:08:06,832|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:08:06,833|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:08:07,195|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:08:07,197|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:08:42,396|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:08:42,397|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 17:08:42,398|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:08:42,761|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:08:42,762|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:08:42,763|(INFO)| File: ask_llm | Message: Running chain for keywords.]
[2025-08-22 17:08:43,030|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 17:08:44,470|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 17:08:44,538|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 1 validation error for Keywords
keywords.0
  Input should be a valid string [type=string_type, input_value=('keywords', ['Artificial...PyTorch', 'TensorFlow']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type]
[2025-08-22 17:11:17,656|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:11:17,657|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:11:36,886|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:11:41,213|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:11:42,805|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:11:42,808|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:11:42,809|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:11:43,440|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:11:43,442|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:11:43,443|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:11:44,387|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:11:44,389|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:11:44,389|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:11:45,112|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:11:45,114|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:11:45,153|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:11:46,006|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:11:46,008|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:11:46,010|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:11:46,695|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:11:46,698|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:11:46,700|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:11:47,716|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:11:47,720|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:11:47,721|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:11:48,870|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:11:48,875|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:11:49,501|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:11:49,509|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:12:22,369|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:12:22,380|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 17:12:22,387|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:12:23,856|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:12:23,858|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:12:23,858|(INFO)| File: ask_llm | Message: Running chain for keywords.]
[2025-08-22 17:12:24,069|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 17:12:26,534|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-22 17:12:26,548|(ERROR)| File: job_recommendation | Message: Error while generating keywords: Error code: 400 - {'error': {'message': "Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': "Based on the resume, here are the top 5 keywords that can be used to find the best-suited job:\n\n1. **Artificial Intelligence (AI)**\n2. **Machine Learning (ML)**\n3. **Data Science**\n4. **Python**\n5. **Deep Learning**\n\nThese keywords are extracted from the resume based on the candidate's technical skills, professional experience, and projects, which highlight their expertise in AI, ML, data science, and deep learning using Python."}}]
[2025-08-22 17:12:57,214|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:12:57,217|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 17:12:57,222|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:12:58,524|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:12:58,526|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:12:58,534|(INFO)| File: ask_llm | Message: Running chain for keywords.]
[2025-08-22 17:12:58,543|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 17:12:59,572|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 17:12:59,928|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 17:12:59,931|(ERROR)| File: job_recommendation | Message: Error while generating keywords: Object of type Keywords is not JSON serializable]
[2025-08-22 17:13:32,487|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:13:32,489|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:14:13,472|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:14:24,359|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:27,054|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:27,063|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:27,064|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:27,930|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:27,932|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:27,932|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:29,029|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:29,057|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:29,058|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:30,109|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:30,111|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:30,147|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:31,056|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:31,061|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:31,064|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:32,231|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:32,246|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:32,261|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:33,142|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:33,144|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:33,145|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:33,993|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:33,996|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:34,681|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:14:34,683|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:14:48,872|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:14:52,351|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:53,398|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:53,400|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:53,400|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:53,872|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:53,875|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:53,877|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:54,416|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:54,418|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:54,418|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:54,857|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:54,858|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:54,881|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:55,423|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:55,425|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:55,426|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:55,987|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:55,988|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:55,989|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:56,553|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:56,555|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:56,556|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:14:57,042|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:14:57,044|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:14:57,340|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:14:57,343|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:15:22,841|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:15:22,842|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 17:15:22,844|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:15:23,721|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:15:23,724|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:15:23,725|(INFO)| File: ask_llm | Message: Running chain for keywords.]
[2025-08-22 17:15:24,059|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 17:15:25,452|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-22 17:15:25,458|(ERROR)| File: job_recommendation | Message: Error while generating keywords: Error code: 400 - {'error': {'message': "tool call validation failed: parameters for tool Keywords did not match schema: errors: [missing properties: 'keywords']", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool-use>\n{\n  "tool_call": {\n    "id": "pending",\n    "type": "function",\n    "function": {\n      "name": "Keywords"\n    },\n    "parameters": {\n      "properties": {\n        "keywords": [\n          "Artificial Intelligence",\n          "Machine Learning",\n          "Data Science",\n          "Python",\n          "Deep Learning"\n        ]\n      }\n    }\n  }\n}\n</tool-use>'}}]
[2025-08-22 17:15:52,280|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:15:52,281|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 17:15:52,282|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:15:53,696|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:15:53,721|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:15:53,726|(INFO)| File: ask_llm | Message: Running chain for keywords.]
[2025-08-22 17:15:53,830|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 17:15:55,331|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 17:15:55,588|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 17:15:55,603|(INFO)| File: keywords_cache | Message: Keywords saved to cache for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:15:55,604|(INFO)| File: job_recommendation | Message: ✅ Saved keywords to cache]
[2025-08-22 17:15:55,605|(ERROR)| File: job_recommendation | Message: Error while generating keywords: Object of type Keywords is not JSON serializable]
[2025-08-22 17:16:23,998|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:16:24,006|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:16:47,239|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:16:54,851|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:16:57,457|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:16:57,474|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:16:57,477|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:16:58,680|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:16:58,690|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:16:58,691|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:00,481|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:00,501|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:00,510|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:03,012|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:03,015|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:03,081|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:06,265|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:06,292|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:06,310|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:08,265|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:08,286|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:08,306|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:10,061|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:10,067|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:10,077|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:11,531|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:11,544|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:12,704|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:17:12,707|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:17:31,897|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:17:34,418|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:36,119|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:36,123|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:36,124|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:36,827|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:36,829|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:36,830|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:37,821|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:37,824|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:37,833|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:38,634|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:38,636|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:38,680|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:39,213|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:39,215|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:39,215|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:39,863|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:39,869|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:39,871|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:40,726|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:40,728|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:40,728|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:17:41,194|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:17:41,196|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:17:41,481|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:17:41,483|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:18:31,994|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:19:37,653|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:19:37,667|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:19:51,009|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:19:54,750|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:19:56,203|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:19:56,205|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:19:56,206|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:19:56,805|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:19:56,806|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:19:56,807|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:19:57,426|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:19:57,429|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:19:57,430|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:19:58,067|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:19:58,069|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:19:58,106|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:19:58,739|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:19:58,741|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:19:58,742|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:00,789|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:00,802|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:00,803|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:03,513|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:03,515|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:03,517|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:04,241|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:04,243|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:04,621|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:20:04,624|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:20:16,852|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:20:21,059|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:22,376|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:22,381|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:22,382|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:23,108|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:23,110|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:23,111|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:23,737|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:23,741|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:23,742|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:24,702|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:24,704|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:24,741|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:25,393|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:25,395|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:25,396|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:26,014|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:26,016|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:26,018|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:26,752|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:26,757|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:26,767|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:20:27,445|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:20:27,448|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:20:28,120|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:20:28,126|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:21:12,435|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:21:12,435|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 17:22:30,574|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:22:30,580|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:22:44,627|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:22:48,367|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:22:49,554|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:22:49,556|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:22:49,557|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:22:50,178|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:22:50,181|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:22:50,182|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:22:51,265|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:22:51,266|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:22:51,267|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:22:51,890|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:22:51,892|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:22:51,930|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:22:52,563|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:22:52,566|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:22:52,566|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:22:53,236|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:22:53,239|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:22:53,239|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:22:53,888|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:22:53,892|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:22:53,893|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:22:54,726|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:22:54,730|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:22:55,361|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:22:55,364|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:23:30,640|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:23:30,646|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:23:58,421|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:24:04,450|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:06,557|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:06,581|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:06,582|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:07,709|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:07,727|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:07,728|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:09,125|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:09,129|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:09,130|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:10,017|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:10,020|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:10,099|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:11,192|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:11,195|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:11,200|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:11,975|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:11,976|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:11,977|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:13,901|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:13,903|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:13,904|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:14,667|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:14,670|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:15,513|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:24:15,518|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:24:31,642|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:24:36,897|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:38,738|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:38,740|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:38,741|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:39,576|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:39,579|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:39,580|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:40,242|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:40,245|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:40,246|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:41,016|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:41,019|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:41,066|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:41,927|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:41,930|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:41,932|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:42,678|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:42,680|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:42,681|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:43,367|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:43,368|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:43,369|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:24:44,042|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:24:44,044|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:24:44,578|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:24:44,582|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:24:51,817|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:24:51,821|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:25:13,670|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:25:20,345|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:25:24,406|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:25:24,423|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:25:24,424|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:25:25,970|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:25:25,972|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:25:25,973|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:25:27,687|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:25:27,706|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:25:27,707|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:25:29,589|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:25:29,591|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:25:29,766|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:25:30,898|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:25:30,906|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:25:30,907|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:25:31,941|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:25:31,956|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:25:31,957|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:25:33,198|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:25:33,207|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:25:33,208|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:25:33,995|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:25:33,999|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:25:34,534|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:25:34,554|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:26:40,580|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:26:40,599|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:27:06,381|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:27:11,511|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:27:14,887|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:27:14,890|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:27:14,892|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:27:16,008|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:27:16,030|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:27:16,031|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:27:17,622|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:27:17,626|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:27:17,631|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:27:18,612|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:27:18,623|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:27:18,728|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:27:20,360|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:27:20,366|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:27:20,372|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:27:22,383|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:27:22,385|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:27:22,386|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:27:24,140|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:27:24,143|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:27:24,145|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:27:25,288|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:27:25,293|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:27:25,902|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:27:25,910|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:27:53,118|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:28:01,632|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:03,794|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:03,798|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:03,799|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:05,161|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:05,175|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:05,176|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:06,935|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:06,937|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:06,982|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:08,837|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:08,839|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:08,883|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:10,061|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:10,069|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:10,070|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:11,496|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:11,499|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:11,500|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:12,807|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:12,810|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:12,812|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:13,693|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:13,696|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:14,134|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:28:14,137|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:28:26,981|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:28:30,183|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:31,410|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:31,412|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:31,413|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:31,975|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:31,978|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:31,981|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:32,487|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:32,489|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:32,489|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:33,000|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:33,002|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:33,038|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:33,567|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:33,569|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:33,570|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:34,031|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:34,032|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:34,033|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:34,494|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:34,496|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:34,497|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:28:34,935|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:28:34,938|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:28:35,216|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:28:35,220|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:28:57,421|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:28:57,422|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 17:30:09,385|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:30:09,385|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 17:30:42,813|(INFO)| File: jobs_cache | Message: No cached job response found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:30:42,814|(INFO)| File: job_recommendation | Message: 🔍 No cache found, searching job from linkedin...]
[2025-08-22 17:30:44,549|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-22 17:30:44,877|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:45,192|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-22 17:30:45,495|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:45,822|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-22 17:30:46,977|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:47,015|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-22 17:30:47,175|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 17:30:48,306|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:49,616|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:50,937|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:52,227|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:53,539|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:54,898|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:56,350|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:57,729|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:30:59,041|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:00,379|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:01,724|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:03,055|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:04,461|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:05,776|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:07,111|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:08,412|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:09,798|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:11,098|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:12,949|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:14,315|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:15,611|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:16,974|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:18,367|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:19,693|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:21,001|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:22,363|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:23,731|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:25,066|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:26,414|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:27,741|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:29,057|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:30,393|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:31,723|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:33,056|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:34,367|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:35,674|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:37,001|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:38,333|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:39,669|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:40,974|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:42,338|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:43,670|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:44,997|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:46,355|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:47,696|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:47,714|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 17:31:49,172|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:50,554|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:51,937|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:53,239|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:54,539|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:55,852|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:57,190|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:58,499|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:31:59,806|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:01,134|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:02,464|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:03,799|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:05,141|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:06,455|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:07,799|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:09,150|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:10,464|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:11,813|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:13,163|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:14,494|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:15,824|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:17,133|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:18,472|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:20,114|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:21,411|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:22,758|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:24,149|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:25,485|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:26,775|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:28,076|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:29,805|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:31,386|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/VEwedJgfRrKlPPwBf "HTTP/1.1 200 OK"]
[2025-08-22 17:32:33,742|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/72doY7A4GZTo8dYdg/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-22 17:32:34,960|(INFO)| File: linkedin | Message: ✅ Retrieved 99 items from dataset: 72doY7A4GZTo8dYdg]
[2025-08-22 17:32:38,531|(ERROR)| File: job_recommendation | Message: Error while cleaning job: the JSON object must be str, bytes or bytearray, not list]
[2025-08-22 17:32:38,532|(ERROR)| File: job_recommendation | Message: Error while searching job from the linkedin: 500: the JSON object must be str, bytes or bytearray, not list]
[2025-08-22 17:34:24,523|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:34:24,528|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:34:40,589|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:34:44,148|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:34:45,942|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:34:45,944|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:34:45,945|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:34:46,687|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:34:46,690|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:34:46,694|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:34:47,566|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:34:47,567|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:34:47,568|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:34:48,193|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:34:48,196|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:34:48,235|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:34:48,955|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:34:48,959|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:34:48,960|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:34:49,917|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:34:49,919|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:34:49,919|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:34:50,630|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:34:50,631|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:34:50,632|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:34:51,301|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:34:51,303|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:34:51,688|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:34:51,691|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:35:06,369|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:35:10,505|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:12,136|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:12,138|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:12,139|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:12,807|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:12,810|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:12,811|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:13,518|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:13,520|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:13,521|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:14,176|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:14,179|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:14,216|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:15,247|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:15,264|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:15,268|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:16,686|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:16,689|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:16,690|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:17,351|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:17,353|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:17,354|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:18,014|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:18,017|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:18,387|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:35:18,389|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:35:33,582|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:35:33,589|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:35:47,222|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:35:50,568|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:51,787|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:51,791|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:51,792|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:52,440|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:52,443|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:52,444|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:53,082|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:53,085|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:53,087|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:54,091|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:54,093|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:54,135|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:54,811|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:54,813|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:54,814|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:55,490|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:55,492|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:55,493|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:56,256|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:56,257|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:56,258|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:35:57,762|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:35:57,767|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:35:58,598|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:35:58,603|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:36:16,210|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:36:21,788|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:36:24,496|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:36:24,500|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:36:24,502|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:36:25,972|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:36:25,983|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:36:25,984|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:36:27,228|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:36:27,231|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:36:27,233|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:36:28,310|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:36:28,314|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:36:28,365|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:36:29,663|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:36:29,667|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:36:29,668|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:36:31,239|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:36:31,246|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:36:31,250|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:36:32,127|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:36:32,130|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:36:32,130|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:36:32,802|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:36:32,805|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:36:33,202|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:36:33,205|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:36:52,655|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:36:58,162|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:00,868|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:00,871|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:00,873|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:01,994|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:02,006|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:02,010|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:03,037|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:03,041|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:03,054|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:04,150|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:04,161|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:04,242|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:05,152|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:05,153|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:05,154|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:05,981|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:05,985|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:05,986|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:06,815|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:06,821|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:06,824|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:07,568|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:07,570|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:08,008|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:37:08,010|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:37:23,270|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:37:29,213|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:32,539|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:32,551|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:32,553|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:34,371|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:34,388|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:34,400|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:36,027|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:36,032|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:36,046|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:37,865|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:37,877|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:38,011|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:40,011|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:40,012|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:40,013|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:41,359|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:41,362|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:41,362|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:42,798|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:42,800|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:42,808|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:37:44,092|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:37:44,094|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:37:44,765|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:37:44,768|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:38:22,030|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:38:22,031|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 17:38:35,007|(INFO)| File: jobs_cache | Message: No cached job response found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:38:35,015|(INFO)| File: job_recommendation | Message: 🔍 No cache found, searching job from linkedin...]
[2025-08-22 17:38:36,703|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-22 17:38:37,017|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:37,329|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-22 17:38:37,668|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:38,028|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-22 17:38:39,280|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:39,306|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-22 17:38:39,360|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 17:38:40,613|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:41,981|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:43,342|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:44,677|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:45,995|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:47,331|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:48,690|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:50,111|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:51,510|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:52,848|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:54,171|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:55,480|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:56,916|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:58,262|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:38:59,581|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:00,935|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:02,442|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:03,755|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:05,107|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:06,413|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:07,763|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:09,086|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:10,421|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:11,731|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:13,082|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:14,392|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:15,746|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:17,057|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:18,403|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:19,716|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:21,068|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:22,615|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:24,111|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:25,452|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:26,805|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:28,290|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:29,804|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:34,163|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:35,977|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:37,780|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:39,136|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:39,935|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 17:39:40,552|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:41,958|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:43,311|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:44,661|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:46,143|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:47,490|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:48,852|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:50,337|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:51,651|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:52,985|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:54,359|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:55,732|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:57,158|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:39:58,685|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:00,211|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:01,740|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:03,217|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:04,545|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:05,896|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:07,405|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:08,917|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:10,433|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:11,752|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:13,109|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:14,636|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:16,160|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:17,653|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:18,999|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:20,396|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:21,836|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:23,176|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:24,546|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:26,453|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:27,916|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:29,436|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:30,958|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:32,475|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:34,341|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:35,658|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:37,033|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/aYJZG4nyUviRmkSvg "HTTP/1.1 200 OK"]
[2025-08-22 17:40:37,764|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/aW4EINNh25VNAhy9E/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-22 17:40:45,944|(INFO)| File: linkedin | Message: ✅ Retrieved 99 items from dataset: aW4EINNh25VNAhy9E]
[2025-08-22 17:40:46,480|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 17:40:52,970|(INFO)| File: jobs_cache | Message: Job response cached for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe &  URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:40:52,978|(INFO)| File: job_recommendation | Message: ✅ Saved jobs to cache]
[2025-08-22 17:40:52,979|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-22 17:40:53,704|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:40:53,740|(INFO)| File: job_recommendation | Message: 📦 You already searched for this url so here is the cached result]
[2025-08-22 17:43:46,425|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:43:46,426|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 17:43:52,931|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:43:52,941|(INFO)| File: job_recommendation | Message: 📦 You already searched for this url so here is the cached result]
[2025-08-22 17:43:53,184|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:43:53,207|(INFO)| File: job_recommendation | Message: 📦 You already searched for this url so here is the cached result]
[2025-08-22 17:44:42,043|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:44:42,044|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:44:56,652|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:45:02,162|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:03,734|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:03,737|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:03,738|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:04,393|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:04,394|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:04,395|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:05,031|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:05,032|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:05,033|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:05,939|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:05,944|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:06,045|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:07,492|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:07,494|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:07,495|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:08,280|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:08,282|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:08,283|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:09,125|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:09,128|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:09,132|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:09,856|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:09,858|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:10,319|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:45:10,326|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:45:22,282|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:45:27,940|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:30,079|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:30,081|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:30,083|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:30,927|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:30,929|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:30,929|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:31,777|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:31,780|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:31,791|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:32,783|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:32,787|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:32,914|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:33,840|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:33,842|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:33,843|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:34,740|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:34,742|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:34,744|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:35,667|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:35,681|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:35,690|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:45:36,635|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:45:36,637|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:45:37,371|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:45:37,374|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:46:03,771|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:46:03,791|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:46:22,941|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:46:26,801|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:46:28,091|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:46:28,098|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:46:28,099|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:46:28,942|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:46:28,952|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:46:28,954|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:46:29,945|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:46:29,950|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:46:29,952|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:46:30,628|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:46:30,631|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:46:30,686|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:46:31,319|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:46:31,323|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:46:31,324|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:46:31,954|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:46:31,956|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:46:31,957|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:46:32,554|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:46:32,560|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:46:32,562|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:46:33,330|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:46:33,331|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:46:33,711|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:46:33,715|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:47:29,906|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:47:29,915|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:47:46,164|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:47:52,290|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:47:53,603|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:47:53,605|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:47:53,606|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:47:54,369|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:47:54,371|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:47:54,371|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:47:55,337|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:47:55,351|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:47:55,353|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:47:57,022|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:47:57,023|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:47:57,061|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:47:57,837|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:47:57,839|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:47:57,840|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:47:58,638|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:47:58,642|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:47:58,644|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:47:59,452|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:47:59,455|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:47:59,455|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:48:00,850|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:48:00,852|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:48:01,292|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:48:01,294|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:48:19,240|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:48:24,480|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:48:25,609|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:48:25,612|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:48:25,613|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:48:26,230|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:48:26,231|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:48:26,232|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:48:27,538|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:48:27,539|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:48:27,540|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:48:28,160|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:48:28,162|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:48:28,204|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:48:29,191|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:48:29,192|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:48:29,193|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:48:31,468|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:48:31,481|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:48:31,485|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:48:33,451|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:48:33,464|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:48:33,468|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:48:34,310|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:48:34,314|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:48:35,131|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:48:35,145|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:48:52,017|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:48:59,167|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:01,072|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:01,074|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:01,074|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:01,865|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:01,867|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:01,867|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:02,704|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:02,710|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:02,713|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:04,405|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:04,407|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:04,454|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:05,572|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:05,574|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:05,578|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:06,981|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:06,983|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:06,984|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:07,984|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:07,986|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:07,987|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:09,209|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:09,213|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:09,958|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:49:09,962|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:49:23,652|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:49:31,490|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:34,185|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:34,189|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:34,190|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:35,443|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:35,447|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:35,448|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:36,332|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:36,340|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:36,341|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:37,177|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:37,180|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:37,310|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:38,521|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:38,537|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:38,542|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:39,314|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:39,316|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:39,317|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:40,455|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:40,457|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:40,458|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:49:41,109|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:49:41,112|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:49:41,477|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:49:41,480|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:49:42,519|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:49:42,523|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:50:03,295|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:50:08,235|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:10,860|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:10,863|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:10,864|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:11,514|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:11,517|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:11,518|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:12,163|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:12,165|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:12,167|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:13,003|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:13,010|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:13,081|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:14,153|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:14,156|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:14,156|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:14,815|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:14,817|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:14,817|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:15,578|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:15,580|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:15,580|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:16,537|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:16,539|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:17,645|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:50:17,649|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:50:38,602|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:50:42,530|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:44,267|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:44,275|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:44,284|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:45,192|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:45,196|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:45,201|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:46,211|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:46,214|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:46,216|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:47,201|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:47,204|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:47,303|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:48,413|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:48,423|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:48,428|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:49,753|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:49,754|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:49,762|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:50,851|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:50,855|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:50,855|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:50:52,019|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:50:52,022|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:50:52,816|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:50:52,823|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:51:07,197|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:51:11,666|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:51:12,559|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:51:12,561|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:51:12,562|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:51:12,931|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:51:12,932|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:51:12,933|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:51:13,389|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:51:13,391|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:51:13,392|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:51:14,007|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:51:14,009|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:51:14,035|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:51:14,590|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:51:14,594|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:51:14,595|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:51:15,166|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:51:15,168|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:51:15,170|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:51:15,715|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:51:15,716|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:51:15,717|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:51:16,188|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:51:16,190|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:51:16,485|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:51:16,488|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:53:46,707|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 17:53:46,713|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 17:53:57,895|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:54:01,219|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:03,202|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:03,205|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:03,207|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:03,830|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:03,832|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:03,833|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:05,027|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:05,034|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:05,035|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:06,174|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:06,176|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:06,218|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:07,273|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:07,275|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:07,276|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:08,603|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:08,605|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:08,607|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:09,347|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:09,350|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:09,351|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:10,035|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:10,037|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:10,409|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:54:10,412|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:54:25,242|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:54:30,087|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:32,360|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:32,365|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:32,365|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:34,091|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:34,094|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:34,095|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:35,004|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:35,006|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:35,007|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:36,886|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:36,895|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:37,051|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:38,134|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:38,136|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:38,137|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:38,780|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:38,782|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:38,783|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:39,420|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:39,422|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:39,423|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:54:40,056|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:54:40,057|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:54:40,430|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:54:40,433|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:54:55,552|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 17:54:59,895|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:55:01,747|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:55:01,753|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:55:01,759|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:55:02,895|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:55:02,904|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:55:02,910|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:55:03,838|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:55:03,840|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:55:03,840|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:55:04,555|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:55:04,557|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:55:04,598|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:55:05,402|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:55:05,404|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:55:05,406|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:55:06,045|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:55:06,049|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:55:06,050|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:55:06,950|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:55:06,954|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:55:06,955|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 17:55:07,795|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 17:55:07,799|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 17:55:08,349|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 17:55:08,363|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 17:56:17,739|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:56:17,749|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 17:56:34,591|(INFO)| File: jobs_cache | Message: No cached job response found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/naukri?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:56:36,428|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 201 Created"]
[2025-08-22 17:56:37,715|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:38,037|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-22 17:56:38,440|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:38,765|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-22 17:56:40,136|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-22 17:56:40,170|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 17:56:40,769|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:42,115|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:44,347|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:45,657|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:46,984|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:48,298|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:49,622|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:51,021|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:52,390|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/grljlfmTdrQiENr2O "HTTP/1.1 200 OK"]
[2025-08-22 17:56:52,803|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/kLtVvxj24UVrmH7HA/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-22 17:56:53,643|(INFO)| File: naukri | Message: ✅ Retrieved 70 items from dataset: kLtVvxj24UVrmH7HA]
[2025-08-22 17:56:53,878|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 17:56:54,661|(INFO)| File: job_recommendation | Message: 🔍 No cache found, saving response...]
[2025-08-22 17:56:54,669|(INFO)| File: jobs_cache | Message: Job response cached for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe &  URL: /job-recommendation/naukri?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:56:54,669|(INFO)| File: job_recommendation | Message: ✅ Saved response to cache]
[2025-08-22 17:56:54,670|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-22 17:56:55,298|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/naukri?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:59:41,339|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 17:59:41,340|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 17:59:54,143|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:59:54,151|(INFO)| File: job_recommendation | Message: 📦 You already searched for this url so here is the cached result]
[2025-08-22 17:59:54,469|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 17:59:54,485|(INFO)| File: job_recommendation | Message: 📦 You already searched for this url so here is the cached result]
[2025-08-22 18:02:50,153|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 18:02:50,154|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 18:03:02,574|(INFO)| File: jobs_cache | Message: No cached job response found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 18:03:02,575|(INFO)| File: job_recommendation | Message: 🔍 No cache found, searching job from linkedin...]
[2025-08-22 18:03:04,129|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-22 18:03:04,485|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:04,883|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-22 18:03:05,187|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:05,627|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-22 18:03:06,957|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:07,037|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 18:03:07,273|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-22 18:03:08,350|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:09,690|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:11,053|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:12,399|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:13,731|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:15,088|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:16,436|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:17,775|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:19,129|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:20,455|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:21,790|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:23,095|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:24,419|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:25,742|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:27,082|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:28,411|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:29,761|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:31,085|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:32,429|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:33,760|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:35,089|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:36,425|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:37,795|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:39,143|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:40,534|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:41,935|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:43,256|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:44,593|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:45,905|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:47,240|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:48,563|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:49,868|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:51,176|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:52,575|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:53,889|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:55,203|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:56,517|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:57,848|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:03:59,179|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:00,513|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:01,824|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:03,155|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:04,481|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:05,801|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:07,123|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:07,573|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 18:04:08,479|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:09,850|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:11,171|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:12,482|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:13,818|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:15,144|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:16,466|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:17,796|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:19,123|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:20,436|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:21,748|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:23,163|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:24,482|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:25,795|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:27,121|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:28,467|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:29,812|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:31,138|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:32,447|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:33,780|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:35,109|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:36,431|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:37,759|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:39,084|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:40,404|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:41,727|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:43,060|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:44,404|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/QVcYcvENFHyvM6lDY "HTTP/1.1 200 OK"]
[2025-08-22 18:04:45,053|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/4StjbHmfAwMjB5Z4Y/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-22 18:04:46,573|(INFO)| File: linkedin | Message: ✅ Retrieved 100 items from dataset: 4StjbHmfAwMjB5Z4Y]
[2025-08-22 18:04:46,886|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 18:04:49,760|(INFO)| File: jobs_cache | Message: Job response cached for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe &  URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 18:04:49,761|(INFO)| File: job_recommendation | Message: ✅ Saved jobs to cache]
[2025-08-22 18:04:49,762|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-22 18:04:50,214|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 18:04:50,223|(INFO)| File: job_recommendation | Message: 📦 You already searched for this url so here is the cached result]
[2025-08-22 18:09:26,152|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 18:09:26,153|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 18:09:31,969|(INFO)| File: suggestions_cache | Message: Cached suggestions retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: 20cdc289a1...]
[2025-08-22 18:14:58,933|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 18:14:58,934|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 18:15:12,738|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 18:15:14,473|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 18:15:15,206|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:15:15,208|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 18:15:15,208|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 18:15:15,591|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:15:15,592|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 18:15:15,593|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 18:15:16,073|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:15:16,075|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 18:15:16,076|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 18:15:16,517|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:15:16,518|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 18:15:16,545|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 18:15:17,048|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:15:17,050|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 18:15:17,051|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 18:15:17,532|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:15:17,533|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 18:15:17,534|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 18:15:17,910|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:15:17,911|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 18:15:17,912|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.5, max_tokens: 550]
[2025-08-22 18:15:18,300|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:15:18,301|(INFO)| File: llm_chain | Message: Chain created successfully.]
[2025-08-22 18:15:18,698|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 18:15:18,700|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 18:34:10,876|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 18:34:10,911|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 18:36:14,369|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 18:41:34,391|(INFO)| File: helper | Message: Loaded GROQ API key from environment variables.]
[2025-08-22 18:41:34,695|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 18:41:36,552|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:41:36,556|(INFO)| File: llm | Message: Chain for finding Skill Gap created sucessfully!]
[2025-08-22 18:41:36,557|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 18:41:37,583|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:41:37,585|(INFO)| File: llm | Message: Chain for finding Project Ideas created sucessfully!]
[2025-08-22 18:41:37,586|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 18:41:38,688|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:41:38,690|(INFO)| File: llm | Message: Chain for finding Improvement Areas created sucessfully!]
[2025-08-22 18:41:38,691|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 18:41:39,344|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:41:39,346|(INFO)| File: llm | Message: Chain for finding keywords created sucessfully!]
[2025-08-22 18:41:39,347|(INFO)| File: llm | Message: Final chain for suggestions created sucessfully!]
[2025-08-22 18:41:39,347|(INFO)| File: __init__ | Message: AskLLM instance created !]
[2025-08-22 18:41:39,586|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 18:41:43,290|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 18:41:43,304|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 18:42:17,113|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 18:42:17,114|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 18:42:25,697|(INFO)| File: suggestions_cache | Message: No cached suggestions found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 18:42:25,700|(INFO)| File: llm | Message: Running chain for suggestions.]
[2025-08-22 18:42:25,983|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Analyze the provided resume and identify actionable recommendations to enha...]
[2025-08-22 18:42:25,984|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Carefully analyze the following resume and identify **missing skills** that...]
[2025-08-22 18:42:25,991|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Analyze the following resume. Based on the candidate's skills, education, a...]
[2025-08-22 18:42:27,404|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:42:27,690|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:42:27,970|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:42:27,981|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-22 18:42:27,982|(INFO)| File: suggestions | Message: 🔍 No cache found, saving suggestions...]
[2025-08-22 18:42:27,989|(INFO)| File: suggestions | Message: ✅ Saved suggestions to cache]
[2025-08-22 18:43:38,276|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: d89bcaba7b...]
[2025-08-22 18:43:38,277|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 18:43:43,727|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 18:43:43,737|(INFO)| File: job_recommendation | Message: 📦 You already searched for this url so here is the cached result]
[2025-08-22 18:43:44,039|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 18:43:44,058|(INFO)| File: job_recommendation | Message: 📦 You already searched for this url so here is the cached result]
[2025-08-22 18:44:09,263|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/naukri?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,Deep Learning&location=India]
[2025-08-22 18:44:22,216|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 18:44:22,224|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 18:48:06,372|(INFO)| File: helper | Message: Loaded GROQ API key from environment variables.]
[2025-08-22 18:48:06,614|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 18:48:08,478|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:48:08,481|(INFO)| File: llm | Message: Chain for finding Skill Gap created sucessfully!]
[2025-08-22 18:48:08,483|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 18:48:09,262|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:48:09,265|(INFO)| File: llm | Message: Chain for finding Project Ideas created sucessfully!]
[2025-08-22 18:48:09,267|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 18:48:09,950|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:48:09,953|(INFO)| File: llm | Message: Chain for finding Improvement Areas created sucessfully!]
[2025-08-22 18:48:09,954|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 18:48:10,608|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 18:48:10,612|(INFO)| File: llm | Message: Chain for finding keywords created sucessfully!]
[2025-08-22 18:48:10,614|(INFO)| File: llm | Message: Final chain for suggestions created sucessfully!]
[2025-08-22 18:48:10,614|(INFO)| File: __init__ | Message: AskLLM instance created !]
[2025-08-22 18:48:10,870|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 18:48:14,716|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 18:48:14,719|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 18:49:24,711|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 18:49:24,712|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 18:49:24,712|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 18:49:24,848|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 18:49:26,769|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:49:26,988|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 18:49:26,989|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'AIMessage' object has no attribute 'keywords']
[2025-08-22 18:49:43,829|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 18:49:43,830|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 18:49:43,831|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 18:49:43,840|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 18:49:44,933|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:49:44,952|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 18:49:44,957|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'AIMessage' object has no attribute 'keywords']
[2025-08-22 18:49:59,628|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 18:49:59,631|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 18:49:59,633|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 18:49:59,645|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 18:50:00,590|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:50:00,609|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 18:50:00,618|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'AIMessage' object has no attribute 'keywords']
[2025-08-22 18:51:53,847|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 18:51:53,849|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 18:51:53,850|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 18:51:53,860|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 18:51:54,994|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:51:55,002|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 18:51:55,002|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'AIMessage' object has no attribute 'keywords']
[2025-08-22 18:53:11,228|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 18:53:11,229|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 18:53:11,231|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 18:53:11,242|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 18:53:17,134|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:53:17,151|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 18:53:17,153|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'AIMessage' object has no attribute 'keywords']
[2025-08-22 18:54:52,884|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 18:54:52,885|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 18:54:52,888|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 18:54:52,906|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 18:54:54,091|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:54:54,109|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 18:54:54,110|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'AIMessage' object has no attribute 'keywords']
[2025-08-22 18:55:52,969|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 18:55:52,972|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 18:55:52,973|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 18:55:52,993|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 18:55:53,841|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 18:55:53,859|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 18:55:53,862|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'AIMessage' object has no attribute 'keywords']
[2025-08-22 19:00:36,191|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:00:36,193|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 19:00:36,195|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 19:00:36,206|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 19:00:37,660|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 19:00:37,706|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 19:00:37,726|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'AIMessage' object has no attribute 'keywords']
[2025-08-22 19:00:40,508|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 19:00:40,509|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 19:01:00,903|(INFO)| File: helper | Message: Loaded GROQ API key from environment variables.]
[2025-08-22 19:01:01,136|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:01:02,810|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:01:02,813|(INFO)| File: llm | Message: Chain for finding Skill Gap created sucessfully!]
[2025-08-22 19:01:02,814|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:01:03,550|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:01:03,552|(INFO)| File: llm | Message: Chain for finding Project Ideas created sucessfully!]
[2025-08-22 19:01:03,554|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:01:04,175|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:01:04,178|(INFO)| File: llm | Message: Chain for finding Improvement Areas created sucessfully!]
[2025-08-22 19:01:04,179|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:01:04,791|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:01:04,795|(INFO)| File: llm | Message: Chain for finding keywords created sucessfully!]
[2025-08-22 19:01:04,797|(INFO)| File: llm | Message: Final chain for suggestions created sucessfully!]
[2025-08-22 19:01:04,798|(INFO)| File: __init__ | Message: AskLLM instance created !]
[2025-08-22 19:01:05,009|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 19:01:08,678|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 19:01:08,683|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 19:02:49,870|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:02:49,875|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 19:02:49,877|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 19:02:50,108|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 19:02:50,990|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 19:02:51,144|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 19:02:51,145|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'str' object has no attribute 'keywords']
[2025-08-22 19:08:02,663|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 19:08:02,668|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 19:08:24,369|(INFO)| File: helper | Message: Loaded GROQ API key from environment variables.]
[2025-08-22 19:08:24,675|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:08:26,624|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:08:26,628|(INFO)| File: llm | Message: Chain for finding Skill Gap created sucessfully!]
[2025-08-22 19:08:26,632|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:08:27,352|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:08:27,356|(INFO)| File: llm | Message: Chain for finding Project Ideas created sucessfully!]
[2025-08-22 19:08:27,365|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:08:28,105|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:08:28,107|(INFO)| File: llm | Message: Chain for finding Improvement Areas created sucessfully!]
[2025-08-22 19:08:28,109|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:08:28,891|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:08:28,894|(INFO)| File: llm | Message: Chain for finding keywords created sucessfully!]
[2025-08-22 19:08:28,895|(INFO)| File: llm | Message: Final chain for suggestions created sucessfully!]
[2025-08-22 19:08:28,896|(INFO)| File: __init__ | Message: AskLLM instance created !]
[2025-08-22 19:08:29,181|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 19:08:32,858|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 19:08:32,862|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 19:10:37,139|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:10:37,140|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 19:10:37,142|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 19:10:37,254|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 19:10:38,502|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 19:10:38,598|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'Keywords' object has no attribute 'content']
[2025-08-22 19:11:26,225|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 19:11:26,230|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 19:11:40,082|(INFO)| File: helper | Message: Loaded GROQ API key from environment variables.]
[2025-08-22 19:11:40,313|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:11:43,329|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:11:43,333|(INFO)| File: llm | Message: Chain for finding Skill Gap created sucessfully!]
[2025-08-22 19:11:43,334|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:11:44,086|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:11:44,089|(INFO)| File: llm | Message: Chain for finding Project Ideas created sucessfully!]
[2025-08-22 19:11:44,090|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:11:44,860|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:11:44,864|(INFO)| File: llm | Message: Chain for finding Improvement Areas created sucessfully!]
[2025-08-22 19:11:44,866|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:11:45,533|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:11:45,536|(INFO)| File: llm | Message: Chain for finding keywords created sucessfully!]
[2025-08-22 19:11:45,542|(INFO)| File: llm | Message: Final chain for suggestions created sucessfully!]
[2025-08-22 19:11:45,543|(INFO)| File: __init__ | Message: AskLLM instance created !]
[2025-08-22 19:11:45,960|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 19:11:50,258|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 19:11:50,262|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 19:12:11,270|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:12:11,275|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 19:12:11,277|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 19:12:11,736|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 19:12:13,029|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 19:12:13,306|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'Keywords' object has no attribute 'content']
[2025-08-22 19:12:30,902|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:12:30,904|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 19:12:30,907|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 19:12:30,917|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 19:12:32,340|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"]
[2025-08-22 19:12:32,363|(ERROR)| File: job_recommendation | Message: Error while generating keywords: Error code: 400 - {'error': {'message': "Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': "Based on the resume, here are the top-5 keywords that can be used to find the best-suited job for the candidate:\n\n1. **Artificial Intelligence (AI)**\n2. **Machine Learning (ML)**\n3. **Data Science**\n4. **Python**\n5. **Deep Learning**\n\nThese keywords are extracted from the candidate's summary, technical skills, professional experience, and projects, highlighting their expertise and interests in AI, ML, and data science."}}]
[2025-08-22 19:12:48,152|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:12:48,155|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 19:12:48,158|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 19:12:48,197|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 19:12:49,278|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 19:12:49,305|(ERROR)| File: job_recommendation | Message: Error while generating keywords: 'Keywords' object has no attribute 'content']
[2025-08-22 19:12:56,239|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 19:12:56,244|(INFO)| File: main | Message: Job Recommendation application is shutting down]
[2025-08-22 19:14:10,409|(INFO)| File: helper | Message: Loaded GROQ API key from environment variables.]
[2025-08-22 19:14:10,770|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:14:14,002|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:14:14,008|(INFO)| File: llm | Message: Chain for finding Skill Gap created sucessfully!]
[2025-08-22 19:14:14,020|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:14:15,498|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:14:15,513|(INFO)| File: llm | Message: Chain for finding Project Ideas created sucessfully!]
[2025-08-22 19:14:15,514|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:14:16,554|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:14:16,556|(INFO)| File: llm | Message: Chain for finding Improvement Areas created sucessfully!]
[2025-08-22 19:14:16,563|(INFO)| File: llm_model | Message: Model initialized with name: llama3-8b-8192, temperature: 0.7, max_tokens: 550]
[2025-08-22 19:14:17,688|(INFO)| File: llm_model | Message: Chat prompt template created.]
[2025-08-22 19:14:17,690|(INFO)| File: llm | Message: Chain for finding keywords created sucessfully!]
[2025-08-22 19:14:17,699|(INFO)| File: llm | Message: Final chain for suggestions created sucessfully!]
[2025-08-22 19:14:17,703|(INFO)| File: __init__ | Message: AskLLM instance created !]
[2025-08-22 19:14:18,071|(INFO)| File: helper | Message: Loaded APIFY API key from environment variables.]
[2025-08-22 19:14:24,277|(INFO)| File: main | Message: Starting the Job Recommendation]
[2025-08-22 19:14:24,280|(INFO)| File: main | Message: Redis client initialized successfully]
[2025-08-22 19:14:38,008|(INFO)| File: keywords_cache | Message: No cached keywords found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:14:38,010|(INFO)| File: job_recommendation | Message: 🔍 No cache found, generating keywords...]
[2025-08-22 19:14:38,010|(INFO)| File: llm | Message: Running chain for keywords.]
[2025-08-22 19:14:38,189|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Based on the resume , give me the best job titles or keyword to search for ...]
[2025-08-22 19:14:39,505|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 19:14:39,764|(INFO)| File: job_recommendation | Message: Keywords are generated successfully]
[2025-08-22 19:14:39,768|(INFO)| File: keywords_cache | Message: Keywords saved to cache for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:14:39,769|(INFO)| File: job_recommendation | Message: ✅ Saved keywords to cache]
[2025-08-22 19:14:55,663|(INFO)| File: jobs_cache | Message: No cached job response found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,PyTorch,TensorFlow,Natural Language Processing,Computer Vision&location=indore]
[2025-08-22 19:14:55,665|(INFO)| File: job_recommendation | Message: 🔍 No cache found, searching job from linkedin...]
[2025-08-22 19:14:58,114|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN/runs "HTTP/1.1 201 Created"]
[2025-08-22 19:14:58,548|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:14:58,909|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-22 19:14:59,284|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:14:59,664|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/hKByXkMQaC5Qt9UMN "HTTP/1.1 200 OK"]
[2025-08-22 19:15:01,143|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-22 19:15:01,616|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 19:15:02,065|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:03,453|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:04,790|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:06,121|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:07,443|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:08,781|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:10,105|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:11,422|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:13,080|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:15,423|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:17,028|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:18,629|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:20,203|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:21,535|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:23,224|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:25,243|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:27,013|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:28,332|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:29,687|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:30,999|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:32,335|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:33,650|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:35,020|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:36,334|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:37,635|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:38,951|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:40,299|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:41,629|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:42,964|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:44,267|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:45,696|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:47,008|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:48,325|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:49,645|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:50,950|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:52,269|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:53,580|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:54,902|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:56,211|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:57,526|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:15:58,850|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:00,147|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:01,445|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:01,637|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 19:16:02,762|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:04,466|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:05,773|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:07,100|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:08,441|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:09,794|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:11,123|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:12,452|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:13,786|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:15,089|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:16,405|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:18,955|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:20,530|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:21,939|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:24,023|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:25,403|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:26,745|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:28,148|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:30,908|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:33,523|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:34,897|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:36,266|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:37,657|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:39,111|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:40,463|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:41,827|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:46,332|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:51,482|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:53,453|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:55,039|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:56,397|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:57,774|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:16:59,134|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:17:00,808|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:17:02,184|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:17:02,252|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 19:17:03,527|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:17:04,887|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:17:06,215|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:17:07,608|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:17:10,128|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:17:12,778|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/GGCjW5F0bvHGoWvpF "HTTP/1.1 200 OK"]
[2025-08-22 19:17:14,166|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/XtZ3wocfNmo0lMwDD/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-22 19:17:18,576|(INFO)| File: linkedin | Message: ✅ Retrieved 121 items from dataset: XtZ3wocfNmo0lMwDD]
[2025-08-22 19:17:19,143|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 19:17:23,206|(INFO)| File: jobs_cache | Message: Job response cached for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe &  URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,PyTorch,TensorFlow,Natural Language Processing,Computer Vision&location=indore]
[2025-08-22 19:17:23,207|(INFO)| File: job_recommendation | Message: ✅ Saved jobs to cache]
[2025-08-22 19:17:23,208|(INFO)| File: job_recommendation | Message: Jobs from LinkedIn fetched successfully!]
[2025-08-22 19:17:23,686|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/linkedin?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,PyTorch,TensorFlow,Natural Language Processing,Computer Vision&location=indore]
[2025-08-22 19:17:23,693|(INFO)| File: job_recommendation | Message: 📦 You already searched for this url so here is the cached result]
[2025-08-22 19:18:17,455|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:18:17,455|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 19:18:31,517|(INFO)| File: jobs_cache | Message: No cached job response found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/naukri?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,PyTorch,TensorFlow,Natural Language Processing,Computer Vision&location=indore]
[2025-08-22 19:18:41,060|(INFO)| File: _client | Message: HTTP Request: POST https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk/runs "HTTP/1.1 201 Created"]
[2025-08-22 19:18:41,415|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:41,800|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-22 19:18:42,181|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:42,518|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/acts/alpcnRV9YI9lYVPWk "HTTP/1.1 200 OK"]
[2025-08-22 19:18:43,753|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:43,801|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem/log?stream=1&raw=1 "HTTP/1.1 200 OK"]
[2025-08-22 19:18:43,867|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem?waitForFinish=999999 "HTTP/1.1 200 OK"]
[2025-08-22 19:18:45,095|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:46,466|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:47,830|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:49,186|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:50,500|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:51,846|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:53,197|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:54,534|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:55,900|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:57,246|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/actor-runs/LLI06xR6rJQTxefem "HTTP/1.1 200 OK"]
[2025-08-22 19:18:58,420|(INFO)| File: _client | Message: HTTP Request: GET https://api.apify.com/v2/datasets/l7Dq59ZxYHA5x02hc/items?offset=0&limit=1000 "HTTP/1.1 200 OK"]
[2025-08-22 19:18:59,011|(INFO)| File: naukri | Message: ✅ Retrieved 70 items from dataset: l7Dq59ZxYHA5x02hc]
[2025-08-22 19:18:59,350|(INFO)| File: helper | Message: Parsed using ast.literal_eval]
[2025-08-22 19:19:00,192|(INFO)| File: job_recommendation | Message: 🔍 No cache found, saving response...]
[2025-08-22 19:19:00,197|(INFO)| File: jobs_cache | Message: Job response cached for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe &  URL: /job-recommendation/naukri?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,PyTorch,TensorFlow,Natural Language Processing,Computer Vision&location=indore]
[2025-08-22 19:19:00,198|(INFO)| File: job_recommendation | Message: ✅ Saved response to cache]
[2025-08-22 19:19:00,199|(INFO)| File: job_recommendation | Message: Jobs from naukri fetched successfully!]
[2025-08-22 19:19:00,747|(INFO)| File: jobs_cache | Message: Cached job response retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & URL: /job-recommendation/naukri?keywords=Artificial Intelligence,Machine Learning,Data Science,Python,PyTorch,TensorFlow,Natural Language Processing,Computer Vision&location=indore]
[2025-08-22 19:20:03,979|(INFO)| File: keywords_cache | Message: Cached keywords retrieved for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:20:03,980|(INFO)| File: job_recommendation | Message: 📦 Already Cached keywords]
[2025-08-22 19:20:38,890|(INFO)| File: suggestions_cache | Message: No cached suggestions found for session:5fb4eb6c-6768-4790-ac86-1c021646c5fe & file hash: e4d27a983e...]
[2025-08-22 19:20:38,891|(INFO)| File: llm | Message: Running chain for suggestions.]
[2025-08-22 19:20:38,919|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Analyze the following resume. Based on the candidate's skills, education, a...]
[2025-08-22 19:20:38,931|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Carefully analyze the following resume and identify **missing skills** that...]
[2025-08-22 19:20:38,951|(INFO)| File: llm_chain | Message: Prompt loaded and rendered: Analyze the provided resume and identify actionable recommendations to enha...]
[2025-08-22 19:20:45,061|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 19:20:45,405|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 19:20:45,551|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"]
[2025-08-22 19:20:45,569|(INFO)| File: suggestions | Message: Suggestion generated successfully]
[2025-08-22 19:20:45,572|(INFO)| File: suggestions | Message: 🔍 No cache found, saving suggestions...]
[2025-08-22 19:20:45,583|(INFO)| File: suggestions | Message: ✅ Saved suggestions to cache]
[2025-08-22 19:22:29,102|(INFO)| File: main | Message: Redis client closed successfully]
[2025-08-22 19:22:29,103|(INFO)| File: main | Message: Job Recommendation application is shutting down]
